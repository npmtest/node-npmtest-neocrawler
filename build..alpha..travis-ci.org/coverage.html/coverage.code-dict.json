{"/home/travis/build/npmtest/node-npmtest-neocrawler/test.js":"/* istanbul instrument in package npmtest_neocrawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-neocrawler/lib.npmtest_neocrawler.js":"/* istanbul instrument in package npmtest_neocrawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_neocrawler = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_neocrawler = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-neocrawler/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-neocrawler && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_neocrawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_neocrawler\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_neocrawler.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_neocrawler.rollup.js'] =\n            local.assetsDict['/assets.npmtest_neocrawler.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_neocrawler.__dirname + '/lib.npmtest_neocrawler.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/run.js":"/**\n * ux crawler entrance \n */\n////log setting////////////////////////////////////////////////////////////////////\nvar logging = require('./lib/logging.js'); \n////arguments parse///////////////////////////////////////////////////////////////\nvar userArgv = require('optimist')\n.usage('Usage: $0 -i [instance name] -a [crawl|test|config|proxy|schedule]  -p [num] -l[url] -h')\n.options('i', {\n        'alias' : 'instance',\n        'default' : 'pengtouba',\n        'describe' : 'Specify a instance',\n        'demand' : true\n    })\n.options('a', {\n        'alias' : 'action',\n        'default' : 'crawl',\n        'describe' : 'Specify a action[crawl|test|config|proxy|schedule]',\n        'demand' : true\n    })\n.options('p', {\n        'alias' : 'port',\n        'default' : 2013,\n        'describe' : 'Specify a service port, for config service and proxy router'\n    })\n.options('l', {\n    'alias' : 'link',\n    'default' : '',\n    'describe' : 'Specify a url to test crawling'\n})\n.options('h', {\n        'alias' : 'help',\n        'describe' : 'Help infomation'\n    });\n\nvar options = userArgv.argv;\nif(options['h']){userArgv.showHelp();process.exit();}\nvar settings = require('./instance/'+options['i']+'/'+'settings.json');\nsettings['instance'] = options['i'];\n////log level/////////////////////////////////////////////////////////////////\nvar log_level = 'DEBUG';\nif(settings['log_level'])log_level = settings['log_level'];\n////crawling action///////////////////////////////////////////////////////////\nvar crawling = function(){\n\tvar logger = logging.getLogger('crawling',options['i'],log_level);\n    settings['logger'] = logger;\n    settings['instance'] = options['i'];\n    var spider = new (require('./spider'))(settings);\n\n    spider.start();\n}\n////proxy Service////////////////////////////////////////////////////////////\nvar proxyService = function(){\n\tvar logger = logging.getLogger('proxy-service',options['i'],log_level);\n\tsettings['logger'] = logger;\n\tsettings['port'] = parseInt(options['p']);\n\tvar proxyRouter = new (require('./proxyrouter'))(settings);\n\t\n\tproxyRouter.start();\n}\n////config service////////////////////////////////////////////////////////////\nvar configService = function(){\n\tvar logger = logging.getLogger('config-service',options['i'],log_level);\n\tsettings['logger'] = logger;\n\tsettings['port'] = parseInt(options['p']);\n\tvar webConfig = new(require('./webconfig'))(settings);\n\t\n\twebConfig.start();\t\n}\n////scheduler///////////////////////////////////////////////////////////////\nvar schedule = function(){\n    var logger = logging.getLogger('schedule',options['i'],log_level);\n    settings['logger'] = logger;\n    var scheduler = new (require('./scheduler'))(settings);\n\n    scheduler.start();\n}\n\n////test url/////////////////////////////////////////////////////////////////\nvar testUrl = function(){\n    if(options['l']!=''){\n        var logger = logging.getLogger('crawling-testing',options['i'],'DEBUG');\n        settings['logger'] = logger;\n        settings['test'] = true;\n        settings['use_proxy'] = false;\n        var spider = new (require('./spider'))(settings);\n\n        spider.test(options['l']);\n    }\n}\n\n////route/////////////////////////////////////////////////////////////////////\nswitch(options['a']){\ncase 'crawl':\n\tcrawling();\n\tbreak;\ncase 'proxy':\n\tproxyService();\n\tbreak;\ncase 'config':\n\tconfigService();\n\tbreak;\ncase 'schedule':\n    schedule();\n    break;\ncase 'test':\n    testUrl();\n    break;\ndefault:\n\tuserArgv.showHelp();\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/logging.js":"/**\n * logging, log4js based\n */\n/**\n * logger constructor\n * @param name\n * @param instance\n * @param level\n * @returns {Logger}\n */\nexports.getLogger = function(name,instance,level){\n\tvar log4js = require('log4js'); \n\tlog4js.configure({\n\t\t\t\t\t  \"appenders\": [\n\t\t\t\t\t                {\n\t\t\t\t\t                  \"type\": \"dateFile\",\n\t\t\t\t\t                  \"filename\": \"logs/\"+name+\"-\"+process.pid+\".log\",\n\t\t\t\t\t                  \"pattern\": \"-yyyy-MM-dd\",\n\t\t\t\t\t                  \"alwaysIncludePattern\": false\n\t\t\t\t\t                },\n\t\t\t\t\t                {\n\t\t\t\t\t                  \"type\": \"console\"\n\t\t\t\t\t                }\n\t\t\t\t\t              ]\n\t\t            }, \n\t\t            {cwd: 'instance/'+instance }\n\t\t            );\n\tvar logger = log4js.getLogger(name);\n\tlogger.setLevel(level);\n\treturn logger;\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/crawler.js":"/**\n * Created by cherokee on 14-3-25.\n */\n\nvar retryTimes = 0;\n\nvar spawnIt = function(tryTimes){\n    var spawn = require('child_process').spawn;\n    var runner = spawn('node',['run.js'].concat(process.argv));\n\n    runner.stdout.on('data', function (data) {\n        console.log(data.toString('utf8'));\n    });\n\n    runner.stderr.on('data', function (data) {\n        console.log(data.toString('utf8'));\n    });\n\n    runner.on('exit', function (code, signal) {\n        console.log('Child process exit ：' + code+', '+signal);\n        if(code!==0&&tryTimes<500){\n            console.log('Restart, times: '+(tryTimes++));\n            process.nextTick(function(){spawnIt(tryTimes)});\n            spawn = null;\n        }\n    });\n}\n\nspawnIt(0);\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/httpRequest.js":"/**\n * Created by cherokee on 14-6-16.\n */\n\nvar cheerio = require('cheerio');\nvar urlUtil =  require(\"url\");\nvar iconv = require('iconv-lite');\nvar BufferHelper = require('bufferhelper');\ntry { var unzip = require('zlib').unzip } catch(e) { console.error('unzip not supported') }\ntry { var inflate = require('zlib').inflate } catch(e) { console.error('inflate not supported') }\nvar http = require('http');\nrequire('./jsextend.js');\n\n/**\n * request page\n * callback(err,status_code,content,page_encoding,param)\n*/\nvar request = function(url,referer,cookie,proxy,timeout,isbin,callback,param){\n    var timeOuter = false;\n    var callbackCount = 0;\n    if(proxy){\n        var proxyRouter = proxy.split(':');\n        var __host = proxyRouter[0];\n        var __port = proxyRouter[1];\n        var __path =  url;\n    }else{\n        var urlobj = urlUtil.parse(url);\n        var __host = urlobj['hostname'];\n        var __port = urlobj['port'];\n        var __path = urlobj['path'];\n    }\n    var startTime = new Date();\n    var options = {\n        'host': __host,\n        'port': __port,\n        'path': __path,\n        'method': 'GET',\n        'headers': {\n            \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.57 Safari/537.36\",\n            \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n            //\"Accept-Encoding\":\"gzip,deflate,sdch\",\n            \"Accept-Encoding\":\"gzip\",\n            \"Accept-Language\":\"zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4\"\n        }\n    };\n\n    if(cookie){\n        var cookie_kvarray = [];\n        for(var i=0; i<cookie.length; i++){\n            cookie_kvarray.push(cookie[i]['name']+'='+cookie[i]['value']);\n        }\n        var cookies_str = cookie_kvarray.join(';');\n        if(cookies_str.length>0)options['headers']['Cookie'] = cookies_str;\n    }\n\n    if(referer)options['headers']['Referer'] = referer;\n\n    var req = http.request(options, function(res) {\n        if(res.statusCode==301||res.statusCode==302){\n            if(res.headers['location']){\n                return request(res.headers['location'],referer,cookie,proxy,timeout,isbin,callback,param);\n            }\n        }\n\n        var bufferHelper = new BufferHelper();\n\n//        res.setEncoding('utf8');\n\n        res.on('data', function (chunk) {\n            bufferHelper.concat(chunk);\n        });\n\n        res.on('end', function () {\n            //console.log('Response end, '+url+' use proxy: '+proxy);\n            if(timeOuter){\n                clearTimeout(timeOuter);\n                timeOuter = false;\n            }\n            if(!req)return callback(new Error('time out'),504,null,null,param||callbackCount++);\n            req = null;\n\n            var page_encoding = get_page_encoding(res.headers);\n\n            page_encoding = page_encoding.toLowerCase().replace('\\-','');\n\n            var res_encoding = res.headers['content-encoding'];\n            if (res_encoding == 'gzip' && typeof unzip != 'undefined') {\n                unzip(bufferHelper.toBuffer(), function(err, buff) {\n                    if (!err && buff) {\n                        if(isbin){if(callbackCount<1)callback(null,res.statusCode,buff,page_encoding,param||callbackCount++);}\n                        else {if(callbackCount<1)callback(null,res.statusCode,iconv.decode(buff,page_encoding),page_encoding,param||callbackCount++);}\n                    }else {if(callbackCount<1)callback(new Error('gzip no content '+err),res.statusCode,null,page_encoding,param||callbackCount++);}\n                });\n            } else if (res_encoding == 'deflate' && typeof inflate != 'undefined') {\n                inflate(bufferHelper.toBuffer(), function(err, buff) {\n                    if (!err && buff) {\n                        if(isbin){if(callbackCount<1)callback(null,res.statusCode,buff,page_encoding,param||callbackCount++);}\n                        else {if(callbackCount<1)callback(null,res.statusCode,iconv.decode(buff,page_encoding),page_encoding,param||callbackCount++);}\n                    }else {if(callbackCount<1)callback(new Error('deflate no content '+err),res.statusCode,null,page_encoding,param||callbackCount++);}\n                });\n            } else {\n                if(isbin){if(callbackCount<1)callback(null,res.statusCode,bufferHelper.toBuffer(),page_encoding,param||callbackCount++);}\n                else {if(callbackCount<1)callback(null,res.statusCode,iconv.decode(bufferHelper.toBuffer(),page_encoding),page_encoding,param||callbackCount++);}\n            }\n        });\n    });\n\n    timeOuter = setTimeout(function(){\n        if(req){\n            //console.error('download timeout, '+url+', cost: '+((new Date())-startTime)+'ms ');\n            req.abort();//req.destroy();\n            req = null;\n            if(callbackCount<1)callback(new Error('time out'),504,null,null,param||callbackCount++);\n        }\n    },(timeout||30)*1000);\n\n    req.on('error', function(e) {\n        //console.error('problem with request: ' + e.message+', url:'+url);\n        if(timeOuter){\n            clearTimeout(timeOuter);\n            timeOuter = false;\n        }\n        if(req){\n            req.abort();//req.destroy();\n            req = null;\n            if(callbackCount<1)callback(new Error('request error'),500,null,null,param||callbackCount++);\n        }\n    });\n    req.end();\n}\n\nvar get_page_encoding = function(header){\n    var page_encoding = 'UTF-8';\n    //get the encoding from header\n    if(header['content-type']!=undefined){\n        var contentType = header['content-type'];\n        var patt = new RegExp(\"^.*?charset\\=(.+)$\",\"ig\");\n        var mts = patt.exec(contentType);\n        if (mts != null)\n        {\n            page_encoding = mts[1];\n        }\n    }\n    return page_encoding;\n}\n\nexports.request = request;\n\n/**\n * css extract\n * @param content\n * @param expression\n * @param pick\n * @param callback\n * @returns {*}\n */\nexports.cssExtract = function(content,expression,pick,callback){\n    if(typeof content=='string')var $ = (cheerio.load(content)).root();\n    else var $ = content;\n    var tmp_val = $.find(expression);\n    var val = tmp_val.eq(0);\n    var result;\n    if(pick.startsWith('@')){\n        result = val.attr(pick.slice(1));\n    }\n    else{\n        switch(pick.toLowerCase()){\n            case 'text':\n            case 'innertext':\n                result = val.text();\n                break;\n            case 'html':\n            case 'innerhtml':\n                result = val.html();\n                break;\n        }\n    }\n    //if(result)result = result.replace(/[\\r\\n\\t]/g, \"\").trim();\n    if(result)result = result.trim();\n    return result;\n}\n\n/**\n * return matched group base expression\n * @param content\n * @param expression\n * @param index\n * @returns {*}\n */\nexports.regexExtract = function(content,expression,index){\n    var index = parseInt(index);\n    if(index==0)index=1;\n    var expression = new RegExp(expression,\"ig\");\n    if(index>0){\n        var matched = expression.exec(content);\n        if(matched&&matched.length>index)return matched[index];\n    }else{\n        var arr = [],matched;\n        while (matched = expression.exec(content))\n            arr.push(matched[1]);\n        return arr;\n    }\n\n}\n\nexports.getDom = function(content){\n    return (cheerio.load(content)).root();\n}\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/jsextend.js":"/**\r\n * Created by james on 13-12-5.\r\n * js extend\r\n */\r\n\r\n/**\r\n * remove duplicated item from array\r\n * @returns {Object}\r\n */\r\n//if (!Array.prototype.unique) {\r\n//    Array.prototype.unique = function() {\r\n//        return this.reduce(function(p, c) {\r\n//            if (p.indexOf(c)<0)p.push(c);\r\n//            return p;\r\n//        }, []);\r\n//    };\r\n//}\r\n\r\n/**\r\n * remove duplicated item from array\r\n * @param arr Array\r\n * @returns {*}\r\n */\r\narrayUnique = function(arr) {\r\n    return arr.reduce(function(p, c) {\r\n        if (p.indexOf(c)<0)p.push(c);\r\n        return p;\r\n    }, []);\r\n}\r\n\r\n/**\r\n* shuffle array\r\n*/\r\n//if (!Array.prototype.shuffle) {\r\n//    Array.prototype.shuffle = function() {\r\n//        for(var j, x, i = this.length; i; j = parseInt(Math.random() * i), x = this[--i], this[i] = this[j], this[j] = x);\r\n//        return this;\r\n//    };\r\n//}\r\n\r\n/**\r\n * shuffle array\r\n * @param arr Array\r\n * @returns {*}\r\n */\r\narrayShuffle = function(arr) {\r\n    for(var j, x, i = arr.length; i; j = parseInt(Math.random() * i), x = arr[--i], arr[i] = arr[j], arr[j] = x);\r\n    return arr;\r\n}\r\n\r\n/**\r\n * detect whether string end with some special character\r\n * @param suffix\r\n * @returns {boolean}\r\n */\r\nString.prototype.endsWith = function(suffix) {\r\n    return this.indexOf(suffix, this.length - suffix.length) !== -1;\r\n};\r\n/**\r\n * detect whether string start with some special character\r\n * @param suffix\r\n * @returns {boolean}\r\n */\r\nString.prototype.startsWith = function(suffix) {\r\n    return this.indexOf(suffix,0) === 0;\r\n};\r\n/**\r\n * remove blank around the string\r\n * @returns {string}\r\n */\r\nString.prototype.trim= function(){\r\n    return this.replace(/(^\\s*)|(\\s*$)/g, \"\");\r\n}\r\n\r\n/**\r\n * detect object is empty\r\n * @returns {boolean}\r\n */\r\n//Object.prototype.isEmpty = function() {\r\n//    for (var prop in this) {\r\n//        if (this.hasOwnProperty(prop)) return false;\r\n//    }\r\n//    return true;\r\n//};\r\n/**\r\n * detect object is empty\r\n * @returns {boolean}\r\n */\r\nisEmpty = function(obj){\r\n    for (var prop in obj) {\r\n        if (obj.hasOwnProperty(prop)) return false;\r\n    }\r\n    return true;\r\n}\r\n\r\nclone = function(obj) {\r\n    // Handle the 3 simple types, and null or undefined\r\n    if (null == obj || \"object\" != typeof obj) return obj;\r\n\r\n    // Handle Date\r\n    if (obj instanceof Date) {\r\n        var copy = new Date();\r\n        copy.setTime(obj.getTime());\r\n        return copy;\r\n    }\r\n\r\n    // Handle Array\r\n    if (obj instanceof Array) {\r\n        var copy = [];\r\n        for (var i = 0,len = obj.length; i < len; ++i) {\r\n            copy[i] = clone(obj[i]);\r\n        }\r\n        return copy;\r\n    }\r\n\r\n    // Handle Object\r\n    if (obj instanceof Object) {\r\n        var copy = {};\r\n        for (var attr in obj) {\r\n            if (obj.hasOwnProperty(attr)) copy[attr] = clone(obj[attr]);\r\n        }\r\n        return copy;\r\n    }\r\n\r\n    throw new Error(\"Unable to copy obj! Its type isn't supported.\");\r\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/line_reader.js":"/**\n * Created by cherokee on 14-5-27.\n */\n(function() {\n    \"use strict\";\n\n    var fs = require('fs'),\n        StringDecoder = require('string_decoder').StringDecoder;\n\n    function LineReader(fd, cb, separator, encoding, bufferSize) {\n        var filePosition   = 0,\n            encoding       = encoding || 'utf8',\n            separator      = separator || '\\n',\n            bufferSize     = bufferSize || 1024,\n            buffer         = new Buffer(bufferSize),\n            bufferStr      = '',\n            decoder        = new StringDecoder(encoding),\n            closed         = false,\n            eof            = false,\n            separatorIndex = -1;\n\n        function close() {\n            if (!closed) {\n                fs.close(fd, function(err) {\n                    if (err) {\n                        throw err;\n                    }\n                });\n                closed = true;\n            }\n        }\n\n        function readToSeparator(cb) {\n            function readChunk() {\n                fs.read(fd, buffer, 0, bufferSize, filePosition, function(err, bytesRead) {\n                    var separatorAtEnd;\n\n                    if (err) {\n                        throw err;\n                    }\n\n                    if (bytesRead < bufferSize) {\n                        eof = true;\n                        close();\n                    }\n\n                    filePosition += bytesRead;\n\n                    bufferStr += decoder.write(buffer.slice(0, bytesRead));\n\n                    if (separatorIndex < 0) {\n                        separatorIndex = bufferStr.indexOf(separator);\n                    }\n\n                    separatorAtEnd = separatorIndex === bufferStr.length - 1;\n                    if (bytesRead && (separatorIndex === -1 || separatorAtEnd) && !eof) {\n                        readChunk();\n                    } else {\n                        cb();\n                    }\n                });\n            }\n\n            readChunk();\n        }\n\n        function hasNextLine() {\n            return bufferStr.length > 0 || !eof;\n        }\n\n        function nextLine(cb) {\n            function getLine() {\n                var ret = bufferStr.substring(0, separatorIndex);\n\n                bufferStr = bufferStr.substring(separatorIndex + 1);\n                separatorIndex = -1;\n                cb(ret);\n            }\n\n            if (separatorIndex < 0) {\n                separatorIndex = bufferStr.indexOf(separator);\n            }\n\n            if (separatorIndex < 0) {\n                if (eof) {\n                    if (hasNextLine()) {\n                        separatorIndex = bufferStr.length;\n                        getLine();\n                    } else {\n                        throw new Error('No more lines to read.');\n                    }\n                } else {\n                    readToSeparator(getLine);\n                }\n            } else {\n                getLine();\n            }\n        }\n\n        this.hasNextLine = hasNextLine;\n        this.nextLine = nextLine;\n        this.close = close;\n\n        readToSeparator(cb);\n    }\n\n    function open(filename, cb, separator, encoding, bufferSize) {\n        fs.open(filename, 'r', parseInt('666', 8), function(err, fd) {\n            var reader;\n            if (err) {\n                throw err;\n            }\n\n            reader = new LineReader(fd, function() {\n                cb(reader);\n            }, separator, encoding, bufferSize);\n        });\n    }\n\n    function eachLine(filename, cb, separator, encoding, bufferSize) {\n        var finalFn,\n            asyncCb = cb.length == 3;\n\n        function finish() {\n            if (finalFn && typeof finalFn === 'function') {\n                finalFn();\n            }\n        }\n\n        open(filename, function(reader) {\n            function newRead() {\n                if (reader.hasNextLine()) {\n                    setImmediate(readNext);\n                } else {\n                    finish();\n                }\n            }\n\n            function continueCb(continueReading) {\n                if (continueReading !== false) {\n                    newRead();\n                } else {\n                    finish();\n                    reader.close();\n                }\n            }\n\n            function readNext() {\n                reader.nextLine(function(line) {\n                    var last = !reader.hasNextLine();\n\n                    if (asyncCb) {\n                        cb(line, last, continueCb);\n                    } else {\n                        if (cb(line, last) !== false) {\n                            newRead();\n                        } else {\n                            finish();\n                            reader.close();\n                        }\n                    }\n                });\n            }\n\n            newRead();\n        }, separator, encoding, bufferSize);\n\n        return {\n            then: function(cb) {\n                finalFn = cb;\n            }\n        };\n    }\n\n    module.exports.open = open;\n    module.exports.eachLine = eachLine;\n}());","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/myredis.js":"/**\n * redis instance\n * Created by cherokee on 14-5-22.\n */\n\nvar redis = require(\"redis\");\nvar ssdb = require(\"./ssdb_redis.js\");\n\nexports.createClient = function(host,port,db,type,callback){\n    if(type=='ssdb'){\n        var ssdb_cli = ssdb.client(host,port);\n        callback(null,ssdb_cli);\n    }else{\n        var redis_cli = redis.createClient(port,host);\n        redis_cli.hlist = function(name,callback){\n            redis_cli.keys(name,callback);\n        };\n        redis_cli.hclear = function(name,callback){\n            redis_cli.del(name,callback);\n        };\n        redis_cli.zlen = function(name,callback){\n            redis_cli.zcount(name,0,(new Date()).getTime(),callback);\n        };\n        redis_cli.zlist = function(name,callback){\n            redis_cli.keys(name,callback);\n        };\n        redis_cli.qlist = function(name,callback){\n            redis_cli.keys(name,callback);\n        };\n        redis_cli.close = function(){\n            redis_cli.quit();\n        };\n        redis_cli.select(db, function(err,value) {\n            callback(err,redis_cli);\n        });\n    }\n}\n\n/*\nexports.createClient('10.1.1.122',1788,0,'ssdb',function(err,c){\n    c.hlist('driller',function(err,values){\n        console.log(err);\n        console.log(values);\n        //c.close();\n    });\n});\n*/","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/ssdb_redis.js":"/**\n * ssdb redis client wrapper\n * Created by cherokee on 14-5-22.\n */\nvar SSDB = require('./SSDB.js');\n\nvar redis_cli = function(host,port){\n    this.ssdb_cli = SSDB.connect(host, port,30*1000,function(err,errobj){\n        if(err)throw errobj;\n    });\n}\n\nredis_cli.prototype.get = function(key,callback){\n    this.ssdb_cli.get(key,callback);\n}\n\nredis_cli.prototype.set = function(key,value,callback){\n    this.ssdb_cli.set(key,value,callback);\n}\n\nredis_cli.prototype.expire = function(key,sec,callback){\n    var self = this;\n    this.ssdb_cli.get(key,function(err,val){\n        self.ssdb_cli.request('setx',[key,val,sec],function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    });\n}\n\nredis_cli.prototype.exists = function(key,callback){\n    this.ssdb_cli.request('exists',[key],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.del = function(key,callback){\n    this.ssdb_cli.del(key,callback);\n}\n\nredis_cli.prototype.keys = function(key,callback){\n    this.ssdb_cli.keys(key,'',-1,callback);\n}\n\nredis_cli.prototype.hlist = function(key,callback){\n    this.ssdb_cli.hlist(key.replace('*','0'),key.replace('*','{'),-1,callback);\n}\n\nredis_cli.prototype.hset = function(key,attr,value,callback){\n    this.ssdb_cli.hset(key,attr,value,callback);\n}\n\nredis_cli.prototype.hgetall = function(key,callback){\n    this.ssdb_cli.request('hscan',[key,'','',-1],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var data = {};\n            for(var i=1; i<resp.length-1; i+=2){\n                data[resp[i].toString()] = resp[i+1].toString();\n            }\n            callback(err, data);\n        }\n    });\n}\n\nredis_cli.prototype.hmset = function(key,values,callback){\n    var valuearr = [key];\n    for(k in values){\n        if(values.hasOwnProperty(k)){\n            if(k!==''&&values[k]!==''){\n                valuearr.push(k);\n                valuearr.push(values[k]);\n            }\n        }\n    }\n    this.ssdb_cli.request('multi_hset',valuearr,function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.hdel = function(key,attr,callback){\n    this.ssdb_cli.hdel(key,attr,callback);\n}\n\nredis_cli.prototype.hclear = function(key,callback){\n    this.ssdb_cli.request('hclear',[key],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.zadd = function(name,score,key,callback){\n    this.ssdb_cli.request('zset',[name,key,score],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.zscore = function(name,key,callback){\n    this.ssdb_cli.request('zget',[name,key], function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.zrem = function(name,key,callback){\n    this.ssdb_cli.request('zdel',[name,key],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.llen = function(key,callback){\n    this.ssdb_cli.request('qsize',[key], function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.qlist = function(key,callback){\n    this.ssdb_cli.request('qlist',[key.replace('*','0'),key.replace('*','{'),-1],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var data = [];\n            for(var i=1; i<resp.length; i++){\n                var k = resp[i].toString();\n                data.push(k);\n            }\n            callback(err, data);\n        }\n    });\n}\n\nredis_cli.prototype.lpush = function(name,key,callback){\n    this.ssdb_cli.request('qpush_front',[name,key],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.rpush = function(name,key,callback){\n    this.ssdb_cli.request('qpush_back',[name,key],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            callback(err);\n        }\n    });\n}\n\nredis_cli.prototype.lpop = function(name,callback){\n    this.ssdb_cli.request('qpop_front',[name], function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            if(val)val=val.toString();\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.rpop = function(name,callback){\n    this.ssdb_cli.request('qpop_back',[name], function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            if(val)val=val.toString();\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.rpoplpush = function(key1,key2,callback){\n    var self = this;\n    self.rpop(key1,function(err,val){\n        if(err)callback(err);\n        else{\n            self.lpush(key2,val,function(err){\n                if(err)callback(err);\n                else callback(null,true);\n            });\n        }\n    });\n}\n\nredis_cli.prototype.lrange = function(name,start,end,callback){\n    this.ssdb_cli.request('qslice',[name,start,end],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var data = [];\n            for(var i=1; i<resp.length; i++){\n                var k = resp[i].toString();\n                data.push(k);\n            }\n            callback(err, data);\n        }\n    });\n}\n\nredis_cli.prototype.zlen = function(key,callback){\n    this.ssdb_cli.request('zsize',[key], function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var val = resp[1];\n            callback(err, val);\n        }\n    });\n}\n\nredis_cli.prototype.zrange = function(name,start,end,callback){\n    this.ssdb_cli.request('zkeys',[name,'',start,end,-1],function(resp){\n        if(callback){\n            var err = resp[0] == 'ok'? 0 : resp[0];\n            var data = [];\n            for(var i=1; i<resp.length; i++){\n                var k = resp[i].toString();\n                data.push(k);\n            }\n            callback(err, data);\n        }\n    });\n}\n\nredis_cli.prototype.zlist = function(key,callback){\n    this.ssdb_cli.zlist(key.replace('*','0'),key.replace('*','{'),-1,callback);\n}\n\nredis_cli.prototype.close = function(){\n    this.ssdb_cli.close();\n}\n\nredis_cli.prototype.quit = function(){\n    this.ssdb_cli.close();\n}\n\nexports.client = function(host,port){\n    return new redis_cli(host,port);\n};\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/SSDB.js":"/**\n * Copyright (c) 2013, ideawu\n * All rights reserved.\n * @author: ideawu\n * @link: http://www.ideawu.com/\n *\n * SSDB nodejs client SDK.\n */\n\nvar net = require('net');\n\n// timeout: microseconds, if ommitted, it will be treated as listener\n// callback(err, ssdb)\n\nvar SSDBConnect = function(host, port, timeout, listener){\n    var self = this;\n    var recv_buf = new Buffer(0);\n    var callbacks = [];\n    var connected = false;\n\n    if(typeof(timeout) == 'function'){\n        listener = timeout;\n        timeout = 0;\n    }\n    listener = listener || function(){};\n\n    var sock = new net.Socket();\n    sock.on('error', function(e){\n        if(!connected){\n            listener('connect_failed', e);\n        }else{\n            var callback = callbacks.shift();\n            if(callback)callback(['error']);\n        }\n    });\n    sock.connect(port, host, function(){\n        connected = true;\n        sock.setNoDelay(true);\n        sock.setKeepAlive(true);\n        sock.setTimeout(timeout);\n        listener(0, self);\n    });\n\n    self.close = function(){\n        sock.end();\n    }\n\n    self.request = function(cmd, params, callback){\n        var arr = [cmd].concat(params);\n        self.send_request(arr);\n        callbacks.push(callback || function(){});\n    }\n\n    function build_buffer(arr){\n        var bs = [];\n        var size = 0;\n        for(var i = 0; i < arr.length; i++){\n            var arg = arr[i];\n            if(arg instanceof Buffer){\n                //\n            }else{\n                arg = new Buffer(arg.toString());\n            }\n            bs.push(arg);\n            size += arg.length;\n        }\n        var ret = new Buffer(size);\n        var offset = 0;\n        for(var i=0; i<bs.length; i++){\n            bs[i].copy(ret, offset);\n            offset += bs[i].length;\n        }\n        return ret;\n    }\n\n    self.send_request = function(params){\n        var bs = [];\n        for(var i=0;i<params.length;i++){\n            var p = params[i];\n            var len = 0;\n            if(!(p instanceof Buffer)){\n                p = p.toString();\n                bs.push(Buffer.byteLength(p));\n            }else{\n                bs.push(p.length);\n            }\n            bs.push('\\n');\n            bs.push(p);\n            bs.push('\\n');\n        }\n        bs.push('\\n');\n        var req = build_buffer(bs);\n        sock.write(req);\n        //console.log('write ' + req.length + ' bytes');\n        //console.log('write: ' + req);\n    }\n\n    sock.on('data', function(data){\n        recv_buf = build_buffer([recv_buf, data]);\n        while(recv_buf.length > 0){\n            var resp = parse();\n            if(!resp){\n                break;\n            }\n            resp[0] = resp[0].toString();\n            var callback = callbacks.shift();\n            callback(resp);\n        }\n    });\n\n    function memchr(buf, ch, start){\n        start = start || 0;\n        ch = typeof(ch) == 'string'? ch.charCodeAt(0) : ch;\n        for(var i=start; i<buf.length; i++){\n            if(buf[i] == ch){\n                return i;\n            }\n        }\n        return -1;\n    }\n\n    function parse(){\n        var ret = [];\n        var spos = 0;\n        var pos;\n        //console.log('parse: ' + recv_buf.length + ' bytes');\n        while(true){\n            //pos = recv_buf.indexOf('\\n', spos);\n            pos = memchr(recv_buf, '\\n', spos);\n            if(pos == -1){\n                // not finished\n                return null;\n            }\n            var line = recv_buf.slice(spos, pos).toString();\n            spos = pos + 1;\n            line = line.replace(/^\\s+(.*)\\s+$/, '\\1');\n            if(line.length == 0){\n                // parse end\n                //recv_buf = recv_buf.substr(spos);\n                recv_buf = recv_buf.slice(spos);\n                break;\n            }\n            var len = parseInt(line);\n            if(isNaN(len)){\n                // error\n                console.log('error 1');\n                return null;\n            }\n            if(spos + len > recv_buf.length){\n                // not finished\n                //console.log(spos + len, recv_buf.length);\n                //console.log('not finish');\n                return null;\n            }\n            //var data = recv_buf.substr(spos, len);\n            var data = recv_buf.slice(spos, spos + len);\n            spos += len;\n            ret.push(data);\n\n            //pos = recv_buf.indexOf('\\n', spos);\n            pos = memchr(recv_buf, '\\n', spos);\n            if(pos == -1){\n                // not finished\n                console.log('error 3');\n                return null;\n            }\n            // '\\n', or '\\r\\n'\n            //if(recv_buf.charAt(spos) != '\\n' && recv_buf.charAt(spos) != '\\r' && recv_buf.charAt(spos+1) != '\\n'){\n            var cr = '\\r'.charCodeAt(0);\n            var lf = '\\n'.charCodeAt(0);\n            if(recv_buf[spos] != lf && recv_buf[spos] != cr && recv_buf[spos+1] != lf){\n                // error\n                console.log('error 4 ' + recv_buf[spos]);\n                return null;\n            }\n            spos = pos + 1;\n        }\n        return ret;\n    }\n\n    // callback(err, val);\n    // err: 0 on sucess, or error_code(string) on error\n    self.get = function(key, callback){\n        self.request('get', [key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                var val = resp[1];\n                callback(err, val);\n            }\n        });\n    }\n\n    // callback(err);\n    self.set = function(key, val, callback){\n        self.request('set', [key, val], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err);\n    self.del = function(key, callback){\n        self.request('del', [key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err, {index:[], items:{key:score}})\n    self.scan = function(key_start, key_end, limit, callback){\n        self.request('scan', [key_start, key_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length % 2 != 1){\n                    callback('error');\n                }else{\n                    var data = {index: [], items: {}};\n                    for(var i=1; i<resp.length; i+=2){\n                        var k = resp[i].toString();\n                        var v = resp[i+1].toString();\n                        data.index.push(k);\n                        data.items[k] = v;\n                    }\n                    callback(err, data);\n                }\n            }\n        });\n    }\n\n    // callback(err, [])\n    self.keys = function(key_start, key_end, limit, callback){\n        self.request('keys', [key_start, key_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                var data = [];\n                for(var i=1; i<resp.length; i++){\n                    var k = resp[i].toString();\n                    data.push(k);\n                }\n                callback(err, data);\n            }\n        });\n    }\n\n    //////////////////////////////////////////////\n\n    // callback(score)\n    self.zget = function(name, key, callback){\n        self.request('zget', [name, key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length == 2){\n                    var score = parseInt(resp[1]);\n                    callback(err, score);\n                }else{\n                    var score = 0;\n                    callback('error');\n                }\n            }\n        });\n    }\n\n    // callback(size)\n    self.zsize = function(name, callback){\n        self.request('zsize', [name], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length == 2){\n                    var size = parseInt(resp[1]);\n                    callback(err, size);\n                }else{\n                    var score = 0;\n                    callback('error');\n                }\n            }\n        });\n    }\n\n    // callback(err);\n    self.zset = function(name, key, score, callback){\n        self.request('zset', [name, key, score], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err);\n    self.zdel = function(name, key, callback){\n        self.request('zdel', [name, key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err, {index:[], items:{key:score}})\n    self.zscan = function(name, key_start, score_start, score_end, limit, callback){\n        self.request('zscan', [name, key_start, score_start, score_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length % 2 != 1){\n                    callback('error');\n                }else{\n                    var data = {index: [], items: {}};\n                    for(var i=1; i<resp.length; i+=2){\n                        var k = resp[i].toString();\n                        var v = parseInt(resp[i+1]);\n                        data.index.push(k);\n                        data.items[k] = v;\n                    }\n                    callback(err, data);\n                }\n            }\n        });\n    }\n\n    // callback(err, [])\n    self.zlist = function(name_start, name_end, limit, callback){\n        self.request('zlist', [name_start, name_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                var data = [];\n                for(var i=1; i<resp.length; i++){\n                    var k = resp[i].toString();\n                    data.push(k);\n                }\n                callback(err, data);\n            }\n        });\n    }\n\n    // callback(err,sum)\n    self.zsum = function(name, score_start, score_end, callback){\n        self.request('zsum', [name,score_start,score_end], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length == 2){\n                    var size = parseInt(resp[1]);\n                    callback(err, size);\n                }else{\n                    callback('error');\n                }\n            }\n        });\n    }\n\n    //////////////////////////////////////////////\n\n    // callback(val)\n    self.hget = function(name, key, callback){\n        self.request('hget', [name, key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length == 2){\n                    callback(err, resp[1]);\n                }else{\n                    callback('error');\n                }\n            }\n        });\n    }\n\n    // callback(err);\n    self.hset = function(name, key, val, callback){\n        self.request('hset', [name, key, val], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err);\n    self.hdel = function(name, key, callback){\n        self.request('hdel', [name, key], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                callback(err);\n            }\n        });\n    }\n\n    // callback(err, {index:[], items:{key:score}})\n    self.hscan = function(name, key_start, key_end, limit, callback){\n        self.request('hscan', [name, key_start, key_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length % 2 != 1){\n                    callback('error');\n                }else{\n                    var data = {index: [], items: {}};\n                    for(var i=1; i<resp.length; i+=2){\n                        var k = resp[i].toString();\n                        var v = resp[i+1].toString();\n                        data.index.push(k);\n                        data.items[k] = v;\n                    }\n                    callback(err, data);\n                }\n            }\n        });\n    }\n\n    // callback(err, [])\n    self.hlist = function(name_start, name_end, limit, callback){\n        self.request('hlist', [name_start, name_end, limit], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                var data = [];\n                for(var i=1; i<resp.length; i++){\n                    var k = resp[i].toString();\n                    data.push(k);\n                }\n                callback(err, data);\n            }\n        });\n    }\n\n    // callback(size)\n    self.hsize = function(name, callback){\n        self.request('hsize', [name], function(resp){\n            if(callback){\n                var err = resp[0] == 'ok'? 0 : resp[0];\n                if(resp.length == 2){\n                    var size = parseInt(resp[1]);\n                    callback(err, size);\n                }else{\n                    var score = 0;\n                    callback('error');\n                }\n            }\n        });\n    }\n\n    return self;\n}\n\nexports.connect = function(host, port, timeout, listener){\n    return new SSDBConnect(host, port, timeout, listener);\n}\n\n\n/*\n example:\n var SSDB = require('./SSDB.js');\n var ssdb = SSDB.connect(host, port, function(err){\n if(err){\n return;\n }\n ssdb.set('a', new Date(), function(){\n console.log('set a');\n });\n });\n */\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/spider/downloader.js":"/**\r\n * Created by james on 13-11-22.\r\n * download middleware\r\n */\r\nvar util = require('util');\r\nvar urlUtil =  require(\"url\");\r\nvar redis = require(\"redis\");\r\nvar events = require('events');\r\nvar child_process = require('child_process');\r\nvar path = require('path');\r\nvar http = require('http');\r\nrequire('../lib/jsextend.js');\r\nvar iconv = require('iconv-lite');\r\nvar BufferHelper = require('bufferhelper');\r\ntry { var unzip = require('zlib').unzip } catch(e) { /* unzip not supported */ }\r\nvar logger;\r\n\r\n//command signal defined\r\nvar CMD_SIGNAL_CRAWL_SUCCESS = 1;\r\nvar CMD_SIGNAL_CRAWL_FAIL = 3;\r\nvar CMD_SIGNAL_NAVIGATE_EXCEPTION = 2;\r\n\r\nvar downloader = function(spiderCore){\r\n    events.EventEmitter.call(this);//eventemitter inherits\r\n    this.spiderCore = spiderCore;\r\n    this.proxyList = [];\r\n    this.timeout_count = 0;\r\n    logger = spiderCore.settings.logger;\r\n}\r\n\r\nutil.inherits(downloader, events.EventEmitter);//eventemitter inherits\r\n\r\n////report to spidercore standby////////////////////////\r\ndownloader.prototype.assembly = function(callback){\r\n    /*\r\n    var downloader = this;\r\n    var MIN_PROXY_LENGTH = 1000;\r\n    downloader.on('gotProxyList',function(label,proxylist){\r\n        if(proxylist&&proxylist.length>0)downloader.tmp_proxyList = downloader.tmp_proxyList.concat(proxylist);\r\n        switch(label){\r\n            case 'proxy:vip:available:1s':\r\n                if(downloader.tmp_proxyList.length<MIN_PROXY_LENGTH)this.getProxyListFromDb('proxy:vip:available:3s');\r\n                else {\r\n                    downloader.proxyList = downloader.tmp_proxyList;\r\n                    downloader.emit('refreshed_proxy_list',downloader.proxyList);\r\n                }\r\n                break;\r\n            case 'proxy:vip:available:3s':\r\n                if(downloader.tmp_proxyList.length<MIN_PROXY_LENGTH)this.getProxyListFromDb('proxy:public:available:1s');\r\n                else {\r\n                    downloader.proxyList = downloader.tmp_proxyList;\r\n                    downloader.emit('refreshed_proxy_list',downloader.proxyList);\r\n                }\r\n                break;\r\n            case 'proxy:public:available:1s':\r\n                if(downloader.tmp_proxyList.length<MIN_PROXY_LENGTH)this.getProxyListFromDb('proxy:public:available:3s');\r\n                else {\r\n                    downloader.proxyList = downloader.tmp_proxyList;\r\n                    downloader.emit('refreshed_proxy_list',downloader.proxyList);\r\n                }\r\n                break;\r\n            case 'proxy:public:available:3s':\r\n                if(downloader.tmp_proxyList.length<MIN_PROXY_LENGTH)logger.warn(util.format('Only %d proxies !!!',downloader.tmp_proxyList.length));\r\n                if(downloader.tmp_proxyList.length<0)throw new Error('no proxy list');\r\n                else{\r\n                    downloader.proxyList = downloader.tmp_proxyList;\r\n                    downloader.emit('refreshed_proxy_list',downloader.proxyList);\r\n                }\r\n                break;\r\n        }\r\n    });\r\n    this.redis_cli3 = redis.createClient(this.spiderCore.settings['proxy_info_redis_db'][1],this.spiderCore.settings['proxy_info_redis_db'][0]);\r\n    if(this.spiderCore.settings['use_proxy']){\r\n        downloader.redis_cli3.select(downloader.spiderCore.settings['proxy_info_redis_db'][2], function(err,value) {\r\n             if(err)throw(err);\r\n             downloader.refreshProxyList(downloader);\r\n             downloader.on('refreshed_proxy_list',function(proxylist){\r\n                 downloader.spiderCore.emit('standby','downloader');\r\n                 setTimeout(function(){downloader.refreshProxyList(downloader)},10*60*1000);//refresh again after 10 mins\r\n             });\r\n         });\r\n\r\n    }else{\r\n        this.spiderCore.emit('standby','downloader');\r\n    }\r\n    */\r\n    if(callback)callback(null,'done');\r\n}\r\n/**\r\n * refresh proxy list from redis db\r\n * @param downloader\r\n */\r\ndownloader.prototype.refreshProxyList = function(downloader){\r\n    downloader.tmp_proxyList = [];\r\n    downloader.getProxyListFromDb('proxy:vip:available:1s');\r\n}\r\n\r\n/**\r\n * get proxy list from redisdb, emit event\r\n * @param label\r\n */\r\ndownloader.prototype.getProxyListFromDb = function(label){\r\n    var downloader = this;\r\n    logger.debug(util.format('get proxy list from :%s',label));\r\n    downloader.redis_cli3.lrange(label,0,-1,function(err,proxylist){\r\n        if(err)throw(err);\r\n        downloader.emit('gotProxyList',label,proxylist);\r\n    });\r\n}\r\n\r\n////download action/////////////////////\r\ndownloader.prototype.download = function (urlinfo){\r\n    if(urlinfo['jshandle'])this.browseIt(urlinfo);\r\n    else this.downloadIt(urlinfo);\r\n}\r\n\r\ndownloader.prototype.transCookieKvPair = function(json){\r\n    var kvarray = [];\r\n    for(var i=0; i<json.length; i++){\r\n        kvarray.push(json[i]['name']+'='+json[i]['value']);\r\n    }\r\n    return kvarray.join(';');\r\n}\r\n\r\n/**\r\n * download page action use http request\r\n */\r\ndownloader.prototype.downloadItAct = function(urlinfo){\r\n    var spiderCore = this.spiderCore;\r\n    var self = this;\r\n\r\n    var timeOuter = false;\r\n    var pageLink = urlinfo['url'];\r\n    if(urlinfo['redirect'])pageLink = urlinfo['redirect'];\r\n\r\n    var useProxy = false;\r\n    if(urlinfo['urllib']&&spiderCore.settings['use_proxy']===true){\r\n        if(spiderCore.spider.getDrillerRule(urlinfo['urllib'],'use_proxy')===true)useProxy=true;\r\n    }\r\n\r\n    if(useProxy){\r\n        var proxyRouter = spiderCore.settings['proxy_router'].split(':');\r\n        var __host = proxyRouter[0];\r\n        var __port = proxyRouter[1];\r\n        var __path =  pageLink;\r\n    }else{\r\n        var urlobj = urlUtil.parse(pageLink);\r\n        var __host = urlobj['hostname'];\r\n        var __port = urlobj['port'];\r\n        var __path = urlobj['path'];\r\n//        var __path = pageLink;\r\n    }\r\n\r\n\r\n    var startTime = new Date();\r\n    var options = {\r\n        'host': __host,\r\n        'port': __port,\r\n        'path': __path,\r\n        'method': 'GET',\r\n        'headers': {\r\n            \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like NeoCrawler) Chrome/31.0.1650.57 Safari/537.36\",\r\n            \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\r\n            \"Accept-Encoding\":\"gzip\",\r\n            \"Accept-Language\":\"zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4\",\r\n            \"Referer\":urlinfo['referer']||'',\r\n            \"void-proxy\":urlinfo['void_proxy']?urlinfo['void_proxy']:\"\",\r\n            \"Cookie\":this.transCookieKvPair(urlinfo['cookie'])\r\n        }\r\n    };\r\n    logger.debug(util.format('Request start, %s',pageLink));\r\n    var req = http.request(options, function(res) {\r\n        logger.debug(util.format('Response, %s',pageLink));\r\n\r\n        var result = {\r\n            \"remote_proxy\":res.headers['remoteproxy'],\r\n            \"drill_count\":0,\r\n            \"cookie\":res.headers['Cookie'],\r\n            \"url\":urlinfo['url'],\r\n            //\"url\":res.req.path,\r\n            //\"statusCode\":res.statusCode,\r\n            \"origin\":urlinfo\r\n        };\r\n        if(result['url'].startsWith('/'))result['url'] = urlUtil.resolve(pageLink,result['url']);\r\n        result['statusCode'] = res.statusCode;\r\n        if(parseInt(res.statusCode)==301||parseInt(res.statusCode)==302){\r\n            if(res.headers['location']){\r\n                result['origin']['redirect'] = urlUtil.resolve(pageLink,res.headers['location']);\r\n                logger.debug(pageLink+' 301 Moved Permanently to '+res.headers['location']);\r\n            }\r\n        }\r\n\r\n        var compressed = /gzip|deflate/.test(res.headers['content-encoding']);\r\n\r\n        var bufferHelper = new BufferHelper();\r\n//        res.setEncoding('utf8');\r\n\r\n        res.on('data', function (chunk) {\r\n            bufferHelper.concat(chunk);\r\n        });\r\n\r\n        res.on('end', function (chunk) {\r\n            self.timeout_count--;\r\n            if(timeOuter){\r\n                clearTimeout(timeOuter);\r\n                timeOuter = false;\r\n            }\r\n            result[\"cost\"] = (new Date()) - startTime;\r\n            logger.debug('download '+pageLink+', cost:'+result[\"cost\"]+'ms');\r\n\r\n\r\n            var page_encoding = urlinfo['encoding'];\r\n\r\n            if(page_encoding==='auto'){\r\n                page_encoding = self.get_page_encoding(res.headers);\r\n            }\r\n\r\n            page_encoding = page_encoding.toLowerCase().replace('\\-','')\r\n            if(!compressed || typeof unzip == 'undefined'){\r\n                if(urlinfo['format']=='binary'){\r\n                    result[\"content\"] = bufferHelper.toBuffer();\r\n                }else{\r\n                    result[\"content\"] = iconv.decode(bufferHelper.toBuffer(),page_encoding);//page_encoding\r\n                }\r\n                spiderCore.emit('crawled',result);\r\n            }else{\r\n                unzip(bufferHelper.toBuffer(), function(err, buff) {\r\n                    if (!err && buff) {\r\n                        if(urlinfo['format']=='binary'){\r\n                            result[\"content\"] = buff;\r\n                        }else{\r\n                            result[\"content\"] = iconv.decode(buff,page_encoding);\r\n                        }\r\n                        spiderCore.emit('crawled',result);\r\n                    }else{\r\n                        spiderCore.emit('crawling_failure',urlinfo,'unzip failure');\r\n                    }\r\n                });\r\n            }\r\n        });\r\n    });\r\n\r\n    timeOuter = setTimeout(function(){\r\n        if(req){\r\n            logger.error('Cost '+((new Date())-startTime)+'ms download timeout, '+pageLink);\r\n            req.abort();\r\n            req=null;\r\n            spiderCore.emit('crawling_failure',urlinfo,'download timeout');\r\n            if(self.timeout_count++>spiderCore.settings['spider_concurrency']){logger.fatal('too much timeout, exit.');process.exit(1);}\r\n        }\r\n    },spiderCore.settings['download_timeout']*1000);\r\n\r\n    req.on('error', function(e) {\r\n        logger.error('problem with request: ' + e.message+', url:'+pageLink);\r\n        if(timeOuter){\r\n            clearTimeout(timeOuter);\r\n            timeOuter = false;\r\n        }\r\n        if(req){\r\n            req.abort();\r\n            req = null;\r\n            spiderCore.emit('crawling_failure',urlinfo,e.message);\r\n        }\r\n    });\r\n    req.end();\r\n}\r\n/**\r\n * get page encoding\r\n * @returns {string}\r\n */\r\ndownloader.prototype.get_page_encoding = function(header){\r\n    var page_encoding = 'UTF-8';\r\n    //get the encoding from header\r\n    if(header['content-type']!=undefined){\r\n        var contentType = header['content-type'];\r\n        var patt = new RegExp(\"^.*?charset\\=(.+)$\",\"ig\");\r\n        var mts = patt.exec(contentType);\r\n        if (mts != null)\r\n        {\r\n            page_encoding = mts[1];\r\n        }\r\n    }\r\n    return page_encoding;\r\n}\r\n\r\n/**\r\n * just download html stream\r\n * @param urlinfo\r\n */\r\ndownloader.prototype.downloadIt = function(urlinfo){\r\n    var spiderCore = this.spiderCore;\r\n    var self = this;\r\n    if('download' in spiderCore.spider_extend){\r\n        spiderCore.spider_extend.download(urlinfo,function(err,result){\r\n            if(err==null&&result==null){\r\n                self.downloadItAct(urlinfo);//if all return null, download it use http request\r\n            }else{\r\n                if(err)spiderCore.emit('crawling_failure',urlinfo,err);\r\n                else spiderCore.emit('crawled',result);\r\n            }\r\n        });\r\n    }else self.downloadItAct(urlinfo);\r\n}\r\n/**\r\n * browser simulated, use phantomjs\r\n * @param urlinfo\r\n */\r\ndownloader.prototype.browseIt = function(urlinfo){\r\n    var spiderCore = this.spiderCore;\r\n    if(this.spiderCore.settings['test']){\r\n        urlinfo['test'] = true;\r\n        urlinfo['ipath'] = path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs');\r\n    }\r\n    var useProxy = false;\r\n    if(urlinfo['urllib']&&spiderCore.settings['use_proxy']===true){\r\n        if(spiderCore.spider.getDrillerRule(urlinfo['urllib'],'use_proxy')===true)useProxy=true;\r\n    }\r\n    if(useProxy){\r\n        var phantomjs = child_process.spawn('./phantomjs', [\r\n            '--proxy', this.spiderCore.settings['proxy_router'],\r\n            '--load-images', 'false',\r\n            '--local-to-remote-url-access','true',\r\n            //'--cookies-file',path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs','cookies.log'),\r\n            'phantomjs-bridge.js',\r\n            JSON.stringify(urlinfo)],\r\n            {'cwd':path.join(__dirname,'..', 'lib','phantomjs'),\r\n                'stdio':'pipe'}\r\n        );\r\n    }else{\r\n        var phantomjs = child_process.spawn('./phantomjs', [\r\n            '--load-images', 'false',\r\n            '--local-to-remote-url-access','true',\r\n            //'--cookies-file',path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs','cookies.log'),\r\n            'phantomjs-bridge.js',\r\n            JSON.stringify(urlinfo)],\r\n            {'cwd':path.join(__dirname,'..', 'lib','phantomjs'),\r\n                'stdio':'pipe'}\r\n        );\r\n    }\r\n\r\n    phantomjs.stdin.setEncoding('utf8');\r\n    phantomjs.stdout.setEncoding('utf8');\r\n\r\n    phantomjs.on('error',function(err){logger.error(err);});\r\n\r\n    var feedback = '';\r\n    phantomjs.stdout.on('data', function(data) {\r\n        data = data.trim();\r\n        if(feedback==''&&!data.startsWith('{')){\r\n            logger.warn('phantomjs: '+data);\r\n        }else{\r\n            feedback += data;\r\n            if(data.endsWith('}#^_^#')){\r\n                var emit_string = feedback.slice(0,-5);\r\n                feedback = '';\r\n                phantomjs.emit('feedback',emit_string);\r\n            }\r\n        }\r\n    });\r\n\r\n    phantomjs.on('feedback', function(data) {\r\n        try{\r\n            var feedback = JSON.parse(data);//data.toString('utf8')\r\n        }catch(e){\r\n            logger.error(util.format('Page content parse error: %s',e));\r\n            spiderCore.emit('crawling_break',urlinfo,e.message);\r\n            phantomjs.kill();\r\n            return;\r\n        }\r\n        switch(feedback['signal']){\r\n            case CMD_SIGNAL_CRAWL_SUCCESS:\r\n                spiderCore.emit('crawled',feedback);\r\n                break;\r\n            case CMD_SIGNAL_CRAWL_FAIL:\r\n                logger.error(feedback.url+' crawled fail');\r\n                phantomjs.kill();\r\n                if(feedback['url']==urlinfo['url'])spiderCore.emit('crawling_failure',urlinfo,'phantomjs crawl failure');\r\n                break;\r\n            case CMD_SIGNAL_NAVIGATE_EXCEPTION:\r\n                logger.error(feedback.url+' navigate fail');\r\n                phantomjs.kill();\r\n                break;\r\n            default:\r\n                logger.debug('Phantomjs: '+data);\r\n        }\r\n    });\r\n\r\n    phantomjs.stderr.on('data', function (data) {\r\n        logger.error(data.toString('utf8'));\r\n    });\r\n\r\n    phantomjs.on('exit', function (code) {\r\n        if(code!=0)logger.error('child process exited with code ' + code);\r\n    });\r\n\r\n    phantomjs.on('close', function (signal) {\r\n        if(signal!=0)logger.error('child process closed with signal ' + signal);\r\n    });\r\n\r\n}\r\n////////////////////////////////////////\r\nmodule.exports = downloader;\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/spider/extractor.js":"/**\r\n * Created by james on 13-11-22.\r\n * extract middleware\r\n */\r\n/**\r\n * extract link\r\n * @param crawl_info\r\n */\r\nvar cheerio = require('cheerio')\r\nvar util = require('util');\r\nvar url =  require(\"url\");\r\nvar querystring = require('querystring');\r\nrequire('../lib/jsextend.js');\r\n\r\nvar extractor = function(spiderCore){\r\n    this.spiderCore = spiderCore;\r\n    logger = spiderCore.settings.logger;\r\n    this.cumulative_failure = 0;\r\n}\r\n\r\n////report to spidercore standby////////////////////////\r\nextractor.prototype.assembly = function(callback){\r\n    if(callback)callback(null,'done');\r\n}\r\n\r\n/**\r\n * According rules extracting all links from html string\r\n * @param content\r\n * @param rules\r\n * @returns {Array}\r\n */\r\nextractor.prototype.extract_link = function($,rules){\r\n    var links = [];\r\n    for(var i=0;i<rules.length;i++){\r\n        $(rules[i]).each(function(i, elem) {\r\n            if(elem['name']=='img')links.push($(this).attr('src'));\r\n\t    else links.push($(this).attr('href'));\r\n        });\r\n    }\r\n    return links;\r\n}\r\n/**\r\n * get top level domain\r\n * www.baidu.com -> baidu.com\r\n * @param domain\r\n * @returns string\r\n * @private\r\n */\r\nextractor.prototype.__getTopLevelDomain = function(domain){\r\n    if(!domain)return null;\r\n    var arr = domain.split('.');\r\n    if(arr.length<=2)return domain;\r\n    else return arr.slice(1).join('.');\r\n}\r\n\r\n/**\r\n * url resolv\r\n * @param pageurl\r\n * @param links\r\n * @returns {Array}\r\n */\r\nextractor.prototype.wash_link = function(pageurl,links){\r\n    //url resolve\r\n    var cleaned_link = [];\r\n    for(var i=0;i<links.length;i++){\r\n        if(!links[i])continue;\r\n        var link = links[i].trim();\r\n        if(!(link.startsWith('#')||link.startsWith('javascript')||link.startsWith('void('))){\r\n            try{\r\n                var the_url = url.resolve(pageurl,link);\r\n                if(the_url!=pageurl)cleaned_link.push(the_url);\r\n            }catch(e){\r\n                logger.error('Url resolve error: '+pageurl+', '+link);\r\n            }\r\n\r\n        }\r\n    }\r\n    return arrayUnique(cleaned_link);\r\n}\r\n/**\r\n * detect link which drill rule matched\r\n * @param link\r\n * @returns [alias name,alias]\r\n */\r\nextractor.prototype.detectLink = function(link){\r\n    var urlobj = url.parse(link);\r\n    var result = [];\r\n    var domain = this.__getTopLevelDomain(urlobj['hostname']);\r\n    if(domain && this.spiderCore.spider.driller_rules[domain]!=undefined){\r\n        var alias = this.spiderCore.spider.driller_rules[domain];\r\n        for(a in alias){\r\n            var url_pattern  = decodeURIComponent(alias[a]['url_pattern']);\r\n            var patt = new RegExp(url_pattern);\r\n            if(patt.test(link)){\r\n                result = ['driller:'+domain+':'+a,alias[a]];\r\n                break;\r\n            }\r\n        }\r\n\r\n    }\r\n    return result;\r\n}\r\n\r\n/**\r\n * arrange link array.\r\n * @param links\r\n * @returns {{}}\r\n */\r\nextractor.prototype.arrange_link = function(links){\r\n    var linkobj = {};\r\n    for(var i=0;i<links.length;i++){\r\n        var link = links[i];\r\n        var matched_driller = this.detectLink(link);\r\n        if(matched_driller.length>0){\r\n            var driller_lib = 'urllib:' + matched_driller[0];\r\n            var driller_rule = matched_driller[1];\r\n            if(typeof(driller_rule)!='object')driller_rule = JSON.parse(driller_rule);\r\n            if(linkobj[driller_lib]==undefined)linkobj[driller_lib]=[];\r\n            if(driller_rule['id_parameter']&&driller_rule['id_parameter'].length>0){\r\n                var id_parameter = driller_rule['id_parameter'];\r\n                var urlobj = url.parse(link);\r\n                var parameters = querystring.parse(urlobj.query);\r\n                var new_parameters = {};\r\n                for(var x=0;x<id_parameter.length;x++){\r\n                    var param_name = id_parameter[x];\r\n                    if(x==0&&param_name=='#')break;\r\n                    if(parameters.hasOwnProperty(param_name))new_parameters[param_name] = parameters[param_name];\r\n                }\r\n                urlobj.search = querystring.stringify(new_parameters);\r\n                link = url.format(urlobj);\r\n            }\r\n            linkobj[driller_lib].push(link);\r\n        }\r\n    }\r\n    for(var i in linkobj){\r\n        if(linkobj.hasOwnProperty(i)){\r\n            linkobj[i] = arrayUnique(linkobj[i]);\r\n        }\r\n    }\r\n    return linkobj;\r\n}\r\n\r\n\r\n/**\r\n * generate drill relation string: page->sub page->sub page\r\n * @param crawl_info\r\n * @returns string\r\n */\r\nextractor.prototype.getDrillRelation = function($,crawl_info){\r\n    //var rule = crawl_info['origin']['drill_relation_rule'];//rule: {\"base\":\"content\",\"mode\":\"css\",\"expression\":\"#breadCrumb\",\"pick\":\"innerText\",\"index\":1}\r\n    var rule = this.spiderCore.spider.getDrillerRule(crawl_info['origin']['urllib'],'drill_relation');\r\n    var origin_relation = crawl_info['origin']['drill_relation'];\r\n    if(!origin_relation)origin_relation = '*';\r\n    var new_relation = '*';\r\n    if(rule){\r\n        switch(rule['mode']){\r\n            case 'regex':\r\n                if(rule['base']==='url'){\r\n                    new_relation = this.regexSelector(crawl_info['url'],rule['expression'],rule['index']);\r\n                }else{\r\n                    new_relation = this.regexSelector(crawl_info['content'],rule['expression'],rule['index']);\r\n                }\r\n                break;\r\n            case 'css':\r\n            default:\r\n                new_relation = this.cssSelector($.root(),rule['expression'],rule['pick'],rule['index']);\r\n                break;\r\n        }\r\n    }\r\n    return util.format('%s->%s',origin_relation,new_relation);\r\n}\r\n\r\n/**\r\n * extractor: for now , just extract links\r\n * @param crawl_info\r\n * @returns {*}\r\n */\r\nextractor.prototype.extract = function(crawl_info){\r\n    if(crawl_info['origin']['format']=='binary')return crawl_info;\r\n    var extract_rule = this.spiderCore.spider.getDrillerRule(crawl_info['origin']['urllib'],'extract_rule');\r\n\r\n    if(crawl_info['origin']['drill_rules']||extract_rule['rule']){\r\n        var $ = cheerio.load(crawl_info['content']);\r\n    }\r\n\r\n    if(crawl_info['origin']['drill_rules']){\r\n        if(crawl_info['drill_link']){\r\n            var drill_link = crawl_info['drill_link'];\r\n        }else{\r\n            var drill_link = this.extract_link($,crawl_info['origin']['drill_rules']);\r\n        }\r\n\r\n        var washed_link = this.wash_link(crawl_info['url'],drill_link);\r\n        crawl_info['drill_link'] = this.arrange_link(washed_link);\r\n        if(this.spiderCore.settings['keep_link_relation'])crawl_info['drill_relation'] = this.getDrillRelation($,crawl_info);\r\n    }\r\n\r\n    if(extract_rule['rule']&&!isEmpty(extract_rule['rule'])){\r\n        var extracted_data = this.extract_data(crawl_info['url'],crawl_info['content'],extract_rule,null,$.root());\r\n        crawl_info['extracted_data'] = extracted_data;\r\n    }\r\n    return crawl_info;\r\n}\r\n/**\r\n * extract data\r\n * @param url\r\n * @param content\r\n * @param extract_rule\r\n * @param uppper_data\r\n * @param dom\r\n * @returns {{}}\r\n */\r\nextractor.prototype.extract_data = function(url,content,extract_rule,uppper_data,dom){\r\n    var data = {};\r\n    var self = this;\r\n    if(extract_rule['category'])data['$category'] = extract_rule['category'];\r\n//    if(extract_rule['require'])data['$require'] = extract_rule['require'];\r\n    if(extract_rule['relate'])data['relate'] = uppper_data[extract_rule['relate']];\r\n    for(i in extract_rule['rule']){\r\n        if(extract_rule['rule'].hasOwnProperty(i)){\r\n            var rule = extract_rule['rule'][i];\r\n            var baser = content;\r\n            if(rule['base']==='url')baser = url;\r\n            switch(rule['mode']){\r\n                case 'regex':\r\n                    var tmp_result = this.regexSelector(baser,rule['expression'],rule['index']);\r\n                    data[i] = tmp_result;\r\n                    break;\r\n                case 'xpath':\r\n                    break;\r\n                case 'value':\r\n                    data[i] = rule['expression'];\r\n                    break;\r\n                case 'json':\r\n                    break;\r\n                default://css selector\r\n                    if(dom)baser = dom;\r\n                    else baser = (cheerio.load(content)).root();\r\n                    var pick = rule['pick'];\r\n                    if(rule['subset']){\r\n                        pick = false;\r\n                        (function(k){\r\n                            var result_arr = [];\r\n                            var tmp_result = self.cssSelector(baser,rule['expression'],pick,rule['index']);\r\n                            if(tmp_result){\r\n                                tmp_result.each(function(x, elem) {\r\n                                    var sub_dom = tmp_result.eq(x);\r\n                                    result_arr.push(self.extract_data(url,content,rule['subset'],data,sub_dom));\r\n                                });\r\n                            }\r\n                            if(!isEmpty(result_arr))data[k] = result_arr;\r\n                        })(i);\r\n                    }else{\r\n                        try{\r\n                            var tmp_result = this.cssSelector(baser,rule['expression'],pick,rule['index']);\r\n                            if(tmp_result&&!isEmpty(tmp_result))data[i] = tmp_result;\r\n                        } catch(e){\r\n                            logger.error(url + ' extract field '+ i + ' error:'+e);\r\n                        }\r\n                    }\r\n\r\n            }\r\n            }\r\n    }\r\n    if(extract_rule['require']){\r\n        var lacks = [];\r\n        for(var c=0;c<extract_rule['require'].length;c++){\r\n            var key = extract_rule['require'][c];\r\n            if(typeof(key)==='object'){\r\n                var sublack = self.checksublack(key,data);\r\n                if(sublack.length>0)lacks = lacks.concat(sublack);\r\n            }else{\r\n                if(!data[key]){\r\n                    lacks.push(key);\r\n                    logger.warn(key + ' not found in '+ url + ' extracted data');\r\n                }\r\n            }\r\n        }\r\n        if(!isEmpty(lacks)){\r\n            logger.error(url + ' extracted data lacks of '+lacks.join(','));\r\n            self.spiderCore.spider.redis_cli2.zadd('incomplete:data:url',(new Date()).getTime(),url,function(err,result){\r\n                //nothing\r\n            });\r\n            if('data_lack_alert' in self.spiderCore.spider_extend)self.spiderCore.spider_extend.data_lack_alert(url,lacks);\r\n        }else{\r\n            self.spiderCore.spider.redis_cli2.zrem('incomplete:data:url',url,function(err,result){\r\n                //nothing\r\n            });\r\n        }\r\n    }\r\n    return data;\r\n}\r\n//check sublack\r\nextractor.prototype.checksublack = function(keys,data){\r\n    var sublackarr = [];\r\n    for(var x=0;x<keys.length;x++){\r\n        if(!data[keys[x]]){\r\n            sublackarr.push(keys[x]);\r\n            logger.warn(keys[x] + ' not found in '+ url + ' extracted data');\r\n        }\r\n    }\r\n    if(sublackarr.length===keys.length)return sublackarr;\r\n    else return [];\r\n}\r\n\r\n/**\r\n * extract value base expression\r\n * @param $\r\n * @param expression\r\n * @param pick\r\n * @param index\r\n * @returns {*}\r\n */\r\nextractor.prototype.cssSelector = function($,expression,pick,index){\r\n//    logger.debug('css expression: '+expression);\r\n    if(!index)index=1;\r\n    var real_index = parseInt(index) - 1;\r\n    //if(real_index<0)real_index=0;\r\n    var tmp_val = $.find(expression);\r\n    if(!pick)return tmp_val;\r\n    if(typeof(tmp_val)==='object'){\r\n        if(real_index>=0){\r\n            var val = tmp_val.eq(real_index);\r\n            return this.cssSelectorPicker(val,pick);\r\n        }else{\r\n            var arrayResult = [];\r\n            for(var i=0;i<tmp_val.length;i++){\r\n                var val = tmp_val.eq(i);\r\n                arrayResult.push(this.cssSelectorPicker(val,pick));\r\n            }\r\n            if(arrayResult.length==1)arrayResult = arrayResult[0];\r\n            return arrayResult;\r\n        }\r\n    }else {\r\n        var val = tmp_val;\r\n        return this.cssSelectorPicker(val,pick);\r\n    }\r\n}\r\n/**\r\n * pick value/attribute from element\r\n * @param val\r\n * @param pick\r\n * @returns {*}\r\n */\r\nextractor.prototype.cssSelectorPicker = function(val,pick){\r\n    var result;\r\n    if(pick.startsWith('@')){\r\n        result = val.attr(pick.slice(1));\r\n    }\r\n    else{\r\n        switch(pick.toLowerCase()){\r\n            case 'text':\r\n            case 'innertext':\r\n                result = val.text();\r\n                break;\r\n            case 'html':\r\n            case 'innerhtml':\r\n                result = val.html();\r\n                break;\r\n        }\r\n    }\r\n    //if(result)result = result.replace(/[\\r\\n\\t]/g, \"\").trim();\r\n    if(result)result = result.trim();\r\n    return result;\r\n}\r\n\r\n/**\r\n * return matched group base expression\r\n * @param content\r\n * @param expression\r\n * @param index\r\n * @returns {*}\r\n */\r\nextractor.prototype.regexSelector = function(content,expression,index){\r\n    var index = parseInt(index);\r\n    if(index==0)index=1;\r\n    var expression = new RegExp(expression,\"ig\");\r\n    if(index>0){\r\n        var matched = expression.exec(content);\r\n        if(matched&&matched.length>index)return matched[index];\r\n    }else{\r\n        var arr = [],matched;\r\n        while (matched = expression.exec(content))\r\n            arr.push(matched[1]);\r\n        return arr;\r\n    }\r\n\r\n}\r\n\r\nextractor.prototype.validateContent = function(crawl_info){\r\n    var self = this;\r\n    var result = true;\r\n    var statusCode = parseInt(crawl_info['statusCode']);\r\n    var limitation = 500;\r\n    if(crawl_info['origin']['format']=='binary')limitation = 20;\r\n    if(statusCode===200){\r\n        if(crawl_info['content'].length<limitation){\r\n            logger.error(util.format('Too little content: %s, length:%s',crawl_info['url'],crawl_info['content'].length));\r\n            result = false;\r\n        }\r\n        if(crawl_info['origin']['validation_keywords']){\r\n            for(var i =0;i<crawl_info['origin']['validation_keywords'].length;i++){\r\n                var keyword = crawl_info['origin']['validation_keywords'][i];\r\n                if(crawl_info['content'].indexOf(keyword)<0){\r\n                    logger.error(util.format('%s lacked keyword: %s',crawl_info['url'],keyword));\r\n                    result = false;break;\r\n                }\r\n            }\r\n        }\r\n    }else{\r\n        logger.error(util.format('url:%s, status code: %s',crawl_info['url'],statusCode));\r\n        if(statusCode>300)result=false;//30x,40x,50x\r\n    }\r\n    if(self.spiderCore.settings['to_much_fail_exit']){\r\n        self.cumulative_failure +=  result?-1:1\r\n        if(self.cumulative_failure<0)self.cumulative_failure = 0;\r\n        if(self.cumulative_failure>self.spiderCore.settings['spider_concurrency']*1.5){\r\n            logger.fatal('too much fail, exit. '+self.cumulative_failure);\r\n            process.exit(1);\r\n        }\r\n    }\r\n    return result;\r\n}\r\n\r\nmodule.exports = extractor;\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/spider/pipeline.js":"/**\r\n * Created by james on 13-11-22.\r\n * pipeline middleware\r\n */\r\nvar crypto = require('crypto');\r\nvar redis = require(\"redis\");\r\nvar HBase = require('../lib/node_hbase/index.js');\r\nvar hbase_http = require('hbase');\r\nvar os = require(\"os\");\r\nvar async = require('async');\r\nvar urlUtil =  require(\"url\");\r\nvar querystring = require('querystring');\r\nvar util = require('util');\r\nvar poolModule = require('generic-pool');\r\nrequire('../lib/jsextend.js');\r\n\r\nvar pipeline = function(spiderCore){\r\n    this.spiderCore = spiderCore;\r\n    logger = spiderCore.settings.logger;\r\n}\r\n\r\n////report to spidercore standby////////////////////////\r\npipeline.prototype.assembly = function(callback){\r\n    var spiderCore = this.spiderCore;\r\n    this.hbase_via_http = false;\r\n    if(spiderCore.settings['crawled_hbase_conf'] instanceof Array)this.hbase_via_http  = true;\r\n    if(this.spiderCore.settings['save_content_to_hbase']===true){\r\n        if(this.hbase_via_http){\r\n            this.hbase_cli = hbase_http({\r\n                host:this.spiderCore.settings['crawled_hbase_conf'][0],\r\n                port:this.spiderCore.settings['crawled_hbase_conf'][1]\r\n            });\r\n            this.HBASE_TABLE = this.hbase_cli.getTable(this.spiderCore.settings['crawled_hbase_table']);\r\n            this.HBASE_BIN_TABLE = this.hbase_cli.getTable(this.spiderCore.settings['crawled_hbase_bin_table']);\r\n        }else{\r\n            this.HBASE_POOL = poolModule.Pool({\r\n                name     : 'hbase_pool',\r\n                create   : function(hbase_callback) {\r\n                    logger.debug('Create a hbase connection.');\r\n                    hbase_callback(null,HBase(spiderCore.settings['crawled_hbase_conf']));\r\n                },\r\n                destroy  : function(db) {\r\n                    logger.debug('Destroy a hbase connection.');\r\n                    db = null;\r\n                },\r\n                max      : this.spiderCore.settings['spider_concurrency'],\r\n                idleTimeoutMillis : 30000,\r\n                log : false\r\n            });\r\n//            this.hbase_cli = HBase(this.spiderCore.settings['crawled_hbase_conf']);\r\n            this.HBASE_TABLE = this.spiderCore.settings['crawled_hbase_table'];\r\n            this.HBASE_BIN_TABLE = this.spiderCore.settings['crawled_hbase_bin_table'];\r\n        }\r\n    }\r\n\r\n    this.redis_cli0 = spiderCore.spider.redis_cli0;\r\n    this.redis_cli1 = spiderCore.spider.redis_cli1;\r\n    this.redis_cli2 = spiderCore.spider.redis_cli2;\r\n    if(callback)callback(null,'done');\r\n}\r\n/**\r\n * save links to redis db\r\n * @param page_url\r\n * @param linkobjs\r\n */\r\npipeline.prototype.save_links = function(page_url,version,linkobjs,drill_relation,callback){\r\n    var spiderCore = this.spiderCore;\r\n    var redis_cli0 = this.redis_cli0;\r\n    var redis_cli1 = this.redis_cli1;\r\n    var aliasArr = Object.keys(linkobjs);\r\n    var linkCount = 0;\r\n    var index = 0;\r\n    if(!version)version = (new Date()).getTime();\r\n    async.whilst(\r\n        function () { return index < aliasArr.length; },\r\n        function (cb) {\r\n            var alias = aliasArr[index];\r\n            var links = linkobjs[alias];\r\n            var t_alias_arr = alias.split(':');\r\n            var drill_alias = t_alias_arr[3];\r\n            var domain = t_alias_arr[2];\r\n            if(!spiderCore.spider.driller_rules[domain]||!spiderCore.spider.driller_rules[domain][drill_alias]){\r\n                logger.error(alias+' not in configuration');\r\n                cb(new Error('Drill rule not found'));\r\n            }\r\n            var t_driller_rules = spiderCore.spider.driller_rules[domain][drill_alias];\r\n            if(typeof(t_driller_rules)!='object')t_driller_rules = JSON.parse(t_driller_rules);\r\n            ////////////////////////////////link array/////////////////////////\r\n            var sindex = 0;\r\n            async.whilst(\r\n                function () { return sindex < links.length; },\r\n                function (scb) {\r\n                    var link = links[sindex];\r\n                    linkCount++;\r\n                    /////save a link/////////////////////\r\n                    async.waterfall([\r\n                        //transform link////////////////////////////////\r\n                        function(mcb){\r\n                            var final_link = link;\r\n                            var urlobj = urlUtil.parse(link);\r\n                            if(t_driller_rules['id_parameter']){\r\n                                var id_parameter = t_driller_rules['id_parameter'];\r\n                                if(typeof(id_parameter)!='object')id_parameter = JSON.parse(id_parameter);\r\n                                if(Array.isArray(id_parameter)&&id_parameter.length>0){\r\n                                    var parameters = querystring.parse(urlobj.query);\r\n                                    var new_parameters = {};\r\n                                    for(var x=0;x<id_parameter.length;x++){\r\n                                        var param_name = id_parameter[x];\r\n                                        if(x==0&&param_name=='#')break;\r\n                                        if(parameters.hasOwnProperty(param_name))new_parameters[param_name] = parameters[param_name];\r\n                                    }\r\n                                    urlobj.search = querystring.stringify(new_parameters);\r\n                                    final_link = urlUtil.format(urlobj);\r\n                                }\r\n                            }\r\n                            return mcb(null,final_link);\r\n                        },\r\n                        ////get url info //////////////\r\n                        function(final_link, mcb){\r\n                            if(final_link!=link)logger.debug('Transform: ' + link + ' -> '+final_link);\r\n                            var urlhash = crypto.createHash('md5').update(final_link+'').digest('hex');\r\n                            redis_cli1.hgetall(urlhash,function(err, value){\r\n                                mcb(err,final_link,urlhash,value);\r\n                            });\r\n                        },\r\n                        //check url////////////////////////\r\n                        function(final_link,urlhash,values,mcb){\r\n                            var validate = true;\r\n                            if(values&&!isEmpty(values)){\r\n                                var status = values['status'];\r\n                                var records = values['records']?JSON.parse(values['records']):[];\r\n                                var last = parseInt(values['last']);\r\n                                var t_version = parseInt(values['version']);\r\n                                var type = values['type'];\r\n\r\n                                if(status!='crawled_failure'){\r\n                                    var real_interval = t_driller_rules['schedule_interval']*1000;\r\n                                    if(status=='crawling'||status=='schedule'){\r\n                                        real_interval = 10*60*1000;//url request hang up or interrupted, give opportunity to crawl after 10 minutes.\r\n                                    }\r\n                                    if(status=='hit'){\r\n                                        real_interval = 2*24*60*60*1000;//probably schedule lost, give opportunity to crawl after 2 days.\r\n                                    }\r\n                                    if(status=='crawled_finish'&&type=='branch'&&version>last){\r\n                                        real_interval = 0;\r\n                                        logger.debug(final_link +' got new version after last crawling');\r\n                                    }\r\n                                    if((new Date()).getTime()-last<real_interval){\r\n                                        logger.debug(util.format('ignore %s, last event time:%s, status:%s',final_link,last,status));\r\n                                        validate = false;\r\n                                    }else{\r\n                                        logger.debug(final_link+' should insert into urlqueue');\r\n                                    }\r\n                                }\r\n                                //version update////////////////////////////////////////////////////////////////\r\n                                logger.debug('url info exists, '+link+', just update the version');\r\n                                var ctc = {};\r\n                                if(validate)ctc['status'] = 'hit';\r\n                                if(version>t_version||isNaN(t_version)){\r\n                                    ctc['version'] = version;\r\n                                    logger.debug('update url('+final_link+') version, '+t_version+' -> '+version);\r\n                                }else {\r\n                                    logger.debug(final_link+' keep the version: '+values['version']);\r\n                                }\r\n                                if(!isEmpty(ctc)){\r\n                                    redis_cli1.hmset(urlhash,ctc,function(err, svalue){\r\n                                        if(err){logger.error(err);}\r\n                                        logger.debug('update url('+final_link+') version, '+t_version+' -> '+version);\r\n                                        mcb(err,final_link,validate);\r\n                                    });\r\n                                }else mcb(null,final_link,validate);\r\n                                //////////////////////////////////////////////////////////////////////////////\r\n                            }else{\r\n                                var vv = {\r\n                                    'url':link,\r\n                                    'version':version,\r\n                                    'trace':alias,\r\n                                    'referer':page_url,\r\n                                    'create':(new Date()).getTime(),\r\n                                    'records':JSON.stringify([]),\r\n                                    'last':(new Date()).getTime(),\r\n                                    'status':'hit'\r\n                                }\r\n                                if(spiderCore.settings['keep_link_relation']){\r\n                                    vv['drill_relation'] = drill_relation?drill_relation:'*';\r\n                                }\r\n                                redis_cli1.hmset(urlhash,vv,function(err, value){\r\n                                    if (err) throw(err);\r\n                                    logger.debug(' save new url('+link+') to urlinfo.');\r\n                                    mcb(null,final_link,true);\r\n                                });\r\n                            }\r\n                        },\r\n                        ////save link to urllib////////////\r\n                        function(final_link,validate,mcb){\r\n                            if(validate){\r\n                                redis_cli0.rpush(alias,final_link,function(err, value){\r\n                                    if(err)throw(err);\r\n                                    logger.debug('push url: '+link+' to urllib: '+alias);\r\n                                    mcb(err,value);\r\n                                });\r\n                            }else mcb(null,'done');\r\n                        }\r\n                    ], function (err, result) {\r\n                        sindex++;\r\n                        scb(err);\r\n                    });\r\n                    ////////////////////////////////////\r\n                },\r\n                function (err) {\r\n                    index++;\r\n                    cb(err);\r\n                }\r\n            );\r\n            ///////////////////////////////////////////////////////////////////\r\n        },\r\n        function (err) {\r\n            logger.info('save '+linkCount+' links from '+page_url+' to redis');\r\n            if(callback)callback(null,true);\r\n        }\r\n    );\r\n}\r\n/**\r\n * save content to hbase(default), if pipeline defined in spider_extend, it will be covered.\r\n * @param pageurl\r\n * @param content\r\n * @param referer\r\n * @param urllib\r\n */\r\npipeline.prototype.save_content = function(pageurl,content,extracted_data,js_result,referer,urllib,drill_relation,callback){\r\n    if(this.hbase_via_http)return this.save_content_vhttp(pageurl,content,extracted_data,js_result,referer,urllib,drill_relation,callback);\r\n\r\n    var url_hash = crypto.createHash('md5').update(pageurl+'').digest('hex');\r\n    var spider = os.hostname()+'-'+process.pid;\r\n    var start_time = (new Date()).getTime();\r\n    var self = this;\r\n\r\n    var put = new HBase.Put(url_hash);\r\n    put.add('basic','spider',spider);\r\n    put.add('basic','url',pageurl);\r\n    put.add('basic','referer',referer);\r\n    put.add('basic','urllib',urllib);\r\n    put.add('basic','updated',(new Date()).getTime().toString());\r\n\r\n    if(content&&!isEmpty(content)){\r\n        put.add('basic','content',content);\r\n    }\r\n\r\n    if(drill_relation&&!isEmpty(drill_relation)){\r\n        put.add('basic','drill_relation',drill_relation);\r\n    }\r\n\r\n    if(extracted_data&&!isEmpty(extracted_data)){\r\n        for(d in extracted_data){\r\n            if(extracted_data.hasOwnProperty(d)&&extracted_data[d]!=undefined){\r\n                put.add('data',d,typeof(extracted_data[d])=='object'?JSON.stringify(extracted_data[d]):extracted_data[d]);\r\n            }\r\n        }\r\n    }\r\n\r\n    if(js_result&&!isEmpty(js_result)){\r\n        put.add('data','jsresult',js_result);\r\n    }\r\n\r\n    self.HBASE_POOL.acquire(function(err, db) {\r\n        if(err){\r\n            self.HBASE_POOL.release(db);\r\n            logger.error(pageurl+', connect to hbase error: '+err);\r\n            self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                if(err)throw err;\r\n                logger.debug('append '+pageurl+' to stuck record');\r\n                if(callback)callback(err);\r\n            });\r\n        } else {\r\n            db.put(extracted_data['$category']||this.HBASE_TABLE,put, function (err,res) {\r\n                self.HBASE_POOL.release(db);\r\n                if(err){\r\n                    logger.error(pageurl+', data insert to hbase error: '+err);\r\n                    self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                        if(err)throw err;\r\n                        logger.debug('append '+pageurl+' to stuck record');\r\n                        if(callback)callback(err);\r\n                    });\r\n                }else{\r\n                    logger.info(pageurl+', data insert to hbase cost '+((new Date()).getTime()-start_time)+' ms');\r\n                    self.redis_cli2.zrem('stuck:'+urllib,pageurl,function(err,result){\r\n                        if(err)throw err;\r\n                        logger.debug('remove '+pageurl+' from stuck record');\r\n                        if(callback)callback(err);\r\n                    });\r\n                }\r\n            });\r\n        }\r\n    });\r\n}\r\n/**\r\n * save content via http\r\n * @param pageurl\r\n * @param content\r\n * @param extracted_data\r\n * @param js_result\r\n * @param referer\r\n * @param urllib\r\n * @param drill_relation\r\n * @param callback\r\n */\r\npipeline.prototype.save_content_vhttp = function(pageurl,content,extracted_data,js_result,referer,urllib,drill_relation,callback){\r\n    var url_hash = crypto.createHash('md5').update(pageurl+'').digest('hex');\r\n    var spider = os.hostname()+'-'+process.pid;\r\n    var start_time = (new Date()).getTime();\r\n    var self = this;\r\n\r\n//    var val_cells = [\r\n//                { \"column\":\"basic:spider\",\"timestamp\":Date.now(),\"$\":spider},\r\n//                { \"column\":\"basic:url\",\"timestamp\":Date.now(),\"$\":pageurl},\r\n//                { \"column\":\"basic:content\",\"timestamp\":Date.now(),\"$\":content}\r\n//                ];\r\n    var keylist = ['basic:spider','basic:url','basic:updated'];\r\n    var valuelist = [spider,pageurl,(new Date()).getTime().toString()];\r\n\r\n    if(referer&&!isEmpty(referer)){\r\n        keylist.push('basic:referer');\r\n        valuelist.push(referer);\r\n    }\r\n\r\n    if(urllib&&!isEmpty(urllib)){\r\n        keylist.push('basic:urllib');\r\n        valuelist.push(urllib);\r\n    }\r\n\r\n    if(drill_relation&&!isEmpty(drill_relation)){\r\n        keylist.push('basic:drill_relation');\r\n        valuelist.push(drill_relation);\r\n    }\r\n\r\n    if(content&&!isEmpty(content)){\r\n        keylist.push('basic:content');\r\n        valuelist.push(content);\r\n    }\r\n\r\n    if(extracted_data&&!isEmpty(extracted_data)){\r\n        for(d in extracted_data){\r\n            if(extracted_data.hasOwnProperty(d)&&extracted_data[d]!=undefined){\r\n                keylist.push('data:'+d);\r\n                valuelist.push(typeof(extracted_data[d])=='object'?JSON.stringify(extracted_data[d]):extracted_data[d]);\r\n            }\r\n        }\r\n//            keylist.push('basic:data');\r\n//            valuelist.push(JSON.stringify(extracted_data));\r\n    }\r\n    if(js_result&&!isEmpty(js_result)){\r\n        keylist.push('data:jsresult');\r\n        valuelist.push(js_result);\r\n    }\r\n    var row = this.HBASE_TABLE.getRow(url_hash);\r\n    try{\r\n        row.put(keylist,valuelist,function(err,success){\r\n            logger.info('insert content extracted from '+pageurl+', cost: '+((new Date()).getTime() - start_time)+' ms');\r\n            if(err){\r\n                logger.error(pageurl+', data insert to hbase error: '+err);\r\n                self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                    if(err)throw err;\r\n                    logger.debug('append '+pageurl+' to stuck record');\r\n                    if(callback)callback(err);\r\n                });\r\n            }else{\r\n                logger.info(pageurl+', data insert to hbase cost '+((new Date()).getTime()-start_time)+' ms');\r\n                self.redis_cli2.zrem('stuck:'+urllib,pageurl,function(err,result){\r\n                    if(err)throw err;\r\n                    logger.debug('remove '+pageurl+' from stuck record');\r\n                    if(callback)callback(err);\r\n                });\r\n            }\r\n        });\r\n//        row.put(['basic:spider','basic:url','basic:content'],[spider,pageurl,content],function(err,success){\r\n//            logger.debug('insert content extracted from '+pageurl);\r\n//        });\r\n    }catch(e){\r\n        logger.error(pageurl+', data insert to hbase error: '+e);\r\n        self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n            if(err)throw err;\r\n            logger.debug('append '+pageurl+' to stuck record');\r\n            if(callback)callback(err);\r\n        });\r\n    }\r\n}\r\n\r\npipeline.prototype.save_binary = function(pageurl,content,referer,urllib,drill_relation,callback){\r\n    if(this.hbase_via_http)return this.save_binary_vhttp(pageurl,content,referer,urllib,drill_relation,callback);\r\n\r\n    var url_hash = crypto.createHash('md5').update(pageurl+'').digest('hex');\r\n    var spider = os.hostname()+'-'+process.pid;\r\n    var start_time = (new Date()).getTime();\r\n    var self = this;\r\n\r\n    var put = new HBase.Put(url_hash);\r\n    put.add('basic','spider',spider);\r\n    put.add('basic','url',pageurl);\r\n    put.add('binary','file',content);\r\n    put.add('basic','referer',referer);\r\n    put.add('basic','urllib',urllib);\r\n    put.add('basic','updated',(new Date()).getTime().toString());\r\n\r\n    self.HBASE_POOL.acquire(function(err, db) {\r\n        if(err) {\r\n            self.HBASE_POOL.release(db);\r\n            logger.error(pageurl+', data connect to hbase error: '+err);\r\n            self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                if(err)throw err;\r\n                logger.debug('append '+pageurl+' to stuck record');\r\n                if(callback)callback(err);\r\n            });\r\n        }else{\r\n            db.put(this.HBASE_BIN_TABLE, put, function (err,res) {\r\n                self.HBASE_POOL.release(db);\r\n                if(err){\r\n                    logger.error(pageurl+', data insert to hbase error: '+err);\r\n                    self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                        if(err)throw err;\r\n                        logger.debug('append '+pageurl+' to stuck record');\r\n                        if(callback)callback(err);\r\n                    });\r\n                }else{\r\n                    logger.info(pageurl+', data insert to hbase cost '+((new Date()).getTime()-start_time)+' ms');\r\n                    self.redis_cli2.zrem('stuck:'+urllib,pageurl,function(err,result){\r\n                        if(err)throw err;\r\n                        logger.debug('remove '+pageurl+' from stuck record');\r\n                        if(callback)callback(err);\r\n                    });\r\n                }\r\n            });\r\n        }\r\n    });\r\n}\r\n\r\n/**\r\n * save binary to hbase via http\r\n * @param pageurl\r\n * @param content\r\n * @param referer\r\n * @param urllib\r\n * @param drill_relation\r\n * @param callback\r\n */\r\npipeline.prototype.save_binary_vhttp = function(pageurl,content,referer,urllib,drill_relation,callback){\r\n    var url_hash = crypto.createHash('md5').update(pageurl+'').digest('hex');\r\n    var spider = os.hostname()+'-'+process.pid;\r\n    var start_time = (new Date()).getTime();\r\n    var self = this;\r\n\r\n    var keylist = [\r\n        'basic:spider',\r\n        'basic:url',\r\n        'basic:updated'\r\n    ];\r\n    var valuelist = [\r\n        spider,\r\n        pageurl,\r\n        (new Date()).getTime().toString()\r\n    ];\r\n\r\n    if(referer){\r\n        keylist.push('basic:referer');\r\n        valuelist.push(referer);\r\n    }\r\n\r\n    if(urllib){\r\n        keylist.push('basic:urllib');\r\n        valuelist.push(urllib);\r\n    }\r\n\r\n    if(drill_relation){\r\n        keylist.push('basic:drill_relation');\r\n        valuelist.push(drill_relation);\r\n    }\r\n\r\n    if(content){\r\n        keylist.push('binary:file');\r\n        valuelist.push(content);\r\n    }\r\n\r\n    var row = this.HBASE_BIN_TABLE.getRow(url_hash);\r\n    try{\r\n        row.put(keylist,valuelist,function(err,success){\r\n            logger.info('insert content extracted from '+pageurl+', cost: '+((new Date()).getTime() - start_time)+' ms');\r\n            if(err){\r\n                logger.error(pageurl+', data insert to hbase error: '+err);\r\n                self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n                    if(err)throw err;\r\n                    logger.debug('append '+pageurl+' to stuck record');\r\n                    if(callback)callback(err);\r\n                });\r\n            }else{\r\n                logger.info(pageurl+', data insert to hbase cost '+((new Date()).getTime()-start_time)+' ms');\r\n                self.redis_cli2.zrem('stuck:'+urllib,pageurl,function(err,result){\r\n                    if(err)throw err;\r\n                    logger.debug('remove '+pageurl+' from stuck record');\r\n                    if(callback)callback(err);\r\n                });\r\n            }\r\n        });\r\n    }catch(e){\r\n        logger.error(pageurl+', data insert to hbase error(2): '+e);\r\n        self.redis_cli2.zadd('stuck:'+urllib,(new Date()).getTime(),pageurl,function(err,result){\r\n            if(err)throw err;\r\n            logger.debug('append '+pageurl+' to stuck record');\r\n            if(callback)callback(err);\r\n        });\r\n    }\r\n}\r\n\r\n/**\r\n * pipeline save entrance\r\n * @param extracted_info\r\n */\r\npipeline.prototype.save =function(extracted_info,callback){\r\n    var pipeline = this;\r\n    if(this.spiderCore.settings['test']){\r\n        var fs = require('fs');\r\n        var path = require('path');\r\n        if(extracted_info['origin']['format']=='binary'){\r\n            var dumpfile = path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs','dumpfile.jpg');\r\n            fs.writeFile(dumpfile,extracted_info['content'],'utf8',function(err){\r\n                if (err)throw err;\r\n                logger.debug('Crawling file saved, '+dumpfile);\r\n                if(callback)callback(true);\r\n            });\r\n        }else{\r\n            var htmlfile = path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs','debug-page.html');\r\n            var resultfile = path.join(__dirname,'..', 'instance',this.spiderCore.settings['instance'],'logs','debug-result.json');\r\n            fs.writeFile(htmlfile,extracted_info['content'],'utf8', function (err) {\r\n                if (err)throw err;\r\n                logger.debug('Content saved, '+htmlfile);\r\n                delete extracted_info['content'];\r\n                fs.writeFile(resultfile,JSON.stringify(extracted_info),'utf8',function(err){\r\n                    if (err)throw err;\r\n                    logger.debug('Crawling result saved, '+resultfile);\r\n                    if(callback)callback(true);\r\n                    else process.exit(0);\r\n                });\r\n            });\r\n        }\r\n    }else{\r\n        async.series([\r\n                function(cb){\r\n                    if(extracted_info['drill_link'])pipeline.save_links(extracted_info['url'],extracted_info['origin']['version'],extracted_info['drill_link'],extracted_info['drill_relation'],cb);\r\n                    else cb(null);\r\n                },\r\n                function(cb){\r\n                    if(pipeline.spiderCore.settings['save_content_to_hbase']===true&&extracted_info['origin']['type']=='node'){//type must be node\r\n                        if(extracted_info['origin']['format']=='binary'){\r\n                            pipeline.save_binary(extracted_info['url'],extracted_info['content'],extracted_info['origin']['referer'],extracted_info['origin']['urllib'],extracted_info['drill_relation'],cb);\r\n                        }else{\r\n                            var html_content = extracted_info['content'];\r\n                            if(!extracted_info['origin']['save_page'])html_content = false;\r\n                            pipeline.save_content(\r\n                                extracted_info['url'],\r\n                                html_content,\r\n                                extracted_info['extracted_data'],\r\n                                extracted_info['js_result'],\r\n                                extracted_info['origin']['referer'],\r\n                                extracted_info['origin']['urllib'],\r\n                                extracted_info['drill_relation'],\r\n                                function(s_err){\r\n\t\t\t\t\t                if(!s_err && 'save_content_alert' in pipeline.spiderCore.spider_extend)pipeline.spiderCore.spider_extend.save_content_alert(extracted_info);//report\r\n\t\t\t\t\t                cb(s_err);\r\n\t\t\t\t            });\r\n                        }\r\n                    }else cb(null);\r\n                },\r\n                function(cb){\r\n                    if('pipeline' in pipeline.spiderCore.spider_extend)pipeline.spiderCore.spider_extend.pipeline(extracted_info,cb);//spider extend\r\n                    else cb(null);\r\n                }\r\n             ],\r\n            function(err, results){\r\n                logger.info(extracted_info['url']+', pipeline completed');\r\n                callback(err);\r\n            });\r\n    }\r\n}\r\n\r\nmodule.exports = pipeline;\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/node_hbase/index.js":"// Generated by CoffeeScript 1.8.0\n(function() {\n  module.exports = function(options) {\n    var Client;\n    Client = require('./lib/client');\n    return new Client(options);\n  };\n\n  module.exports.Put = require('./lib/put');\n\n  module.exports.Get = require('./lib/get');\n\n  module.exports.Delete = require('./lib/delete');\n\n  module.exports.Increment = require('./lib/increment');\n\n  module.exports.Scan = require('./lib/scan').Scan;\n\n  module.exports.FilterList = require('./lib/filter-list');\n\n  module.exports.utils = require('./lib/utils');\n\n}).call(this);\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/node_hbase/lib/put.js":"// Generated by CoffeeScript 1.8.0\n(function() {\n  var ByteBuffer, ProtoBuf, Put, builder, proto,\n    __bind = function(fn, me){ return function(){ return fn.apply(me, arguments); }; };\n\n  ProtoBuf = require(\"protobufjs\");\n\n  ByteBuffer = require('protobufjs/node_modules/bytebuffer');\n\n  ProtoBuf.convertFieldsToCamelCase = true;\n\n  builder = ProtoBuf.loadProtoFile(\"\" + __dirname + \"/../proto/Client.proto\");\n\n  proto = builder.build();\n\n  module.exports = Put = (function() {\n    function Put(row, ts) {\n      this.row = row;\n      this.ts = ts;\n      this.getRow = __bind(this.getRow, this);\n      this.getFields = __bind(this.getFields, this);\n      this.add = __bind(this.add, this);\n      this.familyMap = {};\n    }\n\n    Put.prototype.add = function(cf, qualifier, value, timestamp) {\n      var _base;\n      if (timestamp == null) {\n        timestamp = this.ts;\n      }\n      if (timestamp == null) {\n        timestamp = ByteBuffer.Long.MAX_VALUE;\n      }\n      if ((_base = this.familyMap)[cf] == null) {\n        _base[cf] = [];\n      }\n      return this.familyMap[cf].push({\n        qualifier: qualifier,\n        value: value,\n        timestamp: timestamp\n      });\n    };\n\n    Put.prototype.getFields = function() {\n      var cf, o, qualifierValue, _ref;\n      o = {\n        row: this.row,\n        mutateType: \"PUT\",\n        columnValue: []\n      };\n      _ref = this.familyMap;\n      for (cf in _ref) {\n        qualifierValue = _ref[cf];\n        o.columnValue.push({\n          family: cf,\n          qualifierValue: qualifierValue\n        });\n      }\n      return o;\n    };\n\n    Put.prototype.getRow = function() {\n      return this.row;\n    };\n\n    return Put;\n\n  })();\n\n}).call(this);\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/spider/spider.js":"/**\r\n * Created by james on 13-12-5.\r\n * spider middleware\r\n */\r\n\r\nvar crypto = require('crypto');\r\nvar url =  require(\"url\");\r\nvar util = require('util');\r\nvar async = require('async');\r\nvar myredis = require('../lib/myredis.js');\r\n\r\nvar spider = function(spiderCore){\r\n    this.spiderCore = spiderCore;\r\n    this.queue_length = 0;\r\n    this.driller_rules_updated = 0;\r\n    this.driller_rules = {};\r\n    logger = spiderCore.settings.logger;\r\n}\r\n\r\n////report to spidercore standby////////////////////////\r\nspider.prototype.assembly = function(callback){\r\n    var self = this;\r\n    var dbtype = 'redis';\r\n    if(this.spiderCore.settings['use_ssdb'])dbtype = 'ssdb';\r\n    async.series([\r\n        function(cb){\r\n            myredis.createClient(\r\n                self.spiderCore.settings['driller_info_redis_db'][0],\r\n                self.spiderCore.settings['driller_info_redis_db'][1],\r\n                self.spiderCore.settings['driller_info_redis_db'][2],\r\n                dbtype,\r\n                function(err,cli){\r\n                    self.redis_cli0 = cli;\r\n                    cb(err);\r\n                });\r\n        },\r\n        function(cb){\r\n            myredis.createClient(\r\n                self.spiderCore.settings['url_info_redis_db'][0],\r\n                self.spiderCore.settings['url_info_redis_db'][1],\r\n                self.spiderCore.settings['url_info_redis_db'][2],\r\n                dbtype,\r\n                function(err,cli){\r\n                    self.redis_cli1 = cli;\r\n                    cb(err);\r\n                });\r\n        },\r\n        function(cb){\r\n            myredis.createClient(\r\n                self.spiderCore.settings['url_report_redis_db'][0],\r\n                self.spiderCore.settings['url_report_redis_db'][1],\r\n                self.spiderCore.settings['url_report_redis_db'][2],\r\n                dbtype,\r\n                function(err,cli){\r\n                    self.redis_cli2 = cli;\r\n                    cb(err);\r\n                });\r\n        }\r\n    ],function(err,result){\r\n        if(callback)callback(null,'done');\r\n    });\r\n}\r\n/**\r\n * smart parse string to json object deeply(level2)\r\n * @param source\r\n */\r\nspider.prototype.jsonSmartDeepParse = function(obj){\r\n    var dataobj = {};\r\n    var numberPattern = new RegExp(\"^\\-?[0-9]+$\");\r\n    for(i in obj){\r\n        if(obj.hasOwnProperty(i)){\r\n            if(typeof(obj[i])==='string'&&(obj[i].charAt(0)==='{'||obj[i].charAt(0)==='[')){\r\n                dataobj[i] = JSON.parse(obj[i]);\r\n            }else if(numberPattern.test(obj[i])){\r\n                dataobj[i] = parseInt(obj[i]);\r\n            }else if(obj[i]==='true'){\r\n                dataobj[i] = true;\r\n            }else if(obj[i]==='false'){\r\n                dataobj[i] = false;\r\n            }else dataobj[i] = obj[i];\r\n        }\r\n    }\r\n    return dataobj;\r\n}\r\n\r\n//refresh the driller rules//////////////////////////////\r\nspider.prototype.refreshDrillerRules = function(){\r\n    var self = this;\r\n    var redis_cli = this.redis_cli0;\r\n        redis_cli.get('updated:driller:rule',function(err,value){\r\n            if (err)throw(err);\r\n            if(self.driller_rules_updated!==parseInt(value)){//driller is changed\r\n                logger.info('driller rules is changed');\r\n                redis_cli.hlist('driller:*',function(err,values){\r\n                    if (err)throw(err);\r\n                    self.tmp_driller_rules = {};\r\n                    self.tmp_driller_rules_length = values.length;\r\n                    for(var i=0;i<values.length;i++){\r\n                        self.wrapper_rules(values[i]);\r\n                    }\r\n                });\r\n                self.driller_rules_updated=parseInt(value);\r\n            }else{\r\n                logger.debug('driller rules is not changed, queue length: '+self.queue_length);\r\n                setTimeout(function(){self.refreshDrillerRules();},self.spiderCore.settings['check_driller_rules_interval']*1000);\r\n            }\r\n        })\r\n}\r\n//wrapper each rule\r\nspider.prototype.wrapper_rules = function(key){\r\n    var self = this;\r\n    var redis_cli = this.redis_cli0;\r\n    redis_cli.hgetall(key, function(err,value){//for synchronized using object variable\r\n        if(self.tmp_driller_rules==undefined)self.tmp_driller_rules = {};\r\n        var isActive = value['active']=='true'||value['active']==true||value['active']=='1'||value['active']==1?true:false;\r\n        if(isActive||self.spiderCore.settings['test']) {\r\n            logger.info('Load rule: '+key);\r\n            if (self.tmp_driller_rules[value['domain']] == undefined)self.tmp_driller_rules[value['domain']] = {};\r\n            self.tmp_driller_rules[value['domain']][value['alias']] = self.jsonSmartDeepParse(value);\r\n        }else logger.debug('Ignore rule: '+key+', status inactive');\r\n        self.tmp_driller_rules_length--;\r\n        if(self.tmp_driller_rules_length<=0){\r\n            self.driller_rules = self.tmp_driller_rules;\r\n            //self.driller_rules_updated = (new Date()).getTime();\r\n            self.spiderCore.emit('driller_rules_loaded',self.driller_rules);\r\n            setTimeout(function(){self.refreshDrillerRules();},self.spiderCore.settings['check_driller_rules_interval']*1000);\r\n        }\r\n    });\r\n}\r\n\r\n/**\r\n * query drillerrule\r\n * @param id\r\n * @param name\r\n */\r\nspider.prototype.getDrillerRule = function(id,name){\r\n    var splited_id = id.split(':');\r\n    var pos = 1;\r\n    if(splited_id[0]==='urllib')pos = 2;\r\n    if(this.driller_rules[splited_id[pos]][splited_id[pos+1]]&&this.driller_rules[splited_id[pos]][splited_id[pos+1]].hasOwnProperty(name)){\r\n        return this.driller_rules[splited_id[pos]][splited_id[pos+1]][name];\r\n    }else{\r\n        logger.warn(util.format('%s in %s %s, not found',name,splited_id[pos],splited_id[pos+1]));\r\n        return false;\r\n    }\r\n}\r\n/**\r\n * get driller rules dictionary\r\n * @param id\r\n * @returns dict{}\r\n */\r\nspider.prototype.getDrillerRules = function(id){\r\n    var splited_id = id.split(':');\r\n    var pos = 1;\r\n    if(splited_id[0]==='urllib')pos = 2;\r\n    if(this.driller_rules[splited_id[pos]] && this.driller_rules[splited_id[pos]][splited_id[pos+1]]){\r\n        return this.driller_rules[splited_id[pos]][splited_id[pos+1]];\r\n    }else{\r\n        logger.warn(util.format('%s%s, not exists',splited_id[pos],splited_id[pos+1]));\r\n        return null;\r\n    }\r\n}\r\n\r\n////get url////////////////////////////////////////////\r\nspider.prototype.getUrlQueue = function(callback){\r\n    /*\r\n     var urlinfo = {\r\n     \"url\":\"http://list.taobao.com/itemlist/sport2011a.htm?spm=1.6659421.a21471u.6.RQYJRM&&md=5221&cat=50071853&sd=0&as=0&viewIndex=1&atype=b&style=grid&same_info=1&tid=0&olu=yes&isnew=2&smc=1&navid=city&_input_charset=utf-8\",\r\n     \"type\":\"branch\",\r\n     \"referer\":\"http://www.taobao.com\",\r\n     \"cookie\":[],//require('./taobao-cookie-simple.json'),\r\n     \"jshandle\":true,\r\n     \"inject_jquery\":false,\r\n     \"drill_rules\":[\".vm-page-next\",\".general a\",\"a\"],\r\n     \"script\":[\"jsexec_result = document.getElementById('pageJumpto').value;\",\"jsexec_result=document.querySelector('.user-nick').text\"],//[\"jsexec_result = $.map($('.category li a span'),function(n,i) {return $(n).text();});\"],//[\"jsexec_result=document.querySelector('.user-nick').text;\"]\r\n     \"navigate_rule\":[\".vm-page-next\"],\r\n     \"stoppage\":3,\r\n     \"url_lib_id\":\"urllib:driller:taobao.com:list\"\r\n     }\r\n     */\r\n\r\n    var spider = this;\r\n    var redis_driller_db = this.redis_cli0;\r\n    var redis_urlinfo_db = this.redis_cli1;\r\n        redis_driller_db.lpop('queue:scheduled:all',function(err, link){\r\n            //2----------------------------------------------------------------------------------------\r\n            if(!link){\r\n                logger.info('No candidate queue, '+spider.queue_length+' urls in crawling.');\r\n                if('no_queue_alert' in spider.spiderCore.spider_extend)spider.spiderCore.spider_extend.no_queue_alert();\r\n                if(callback){callback(false);return;}\r\n            };//no queue\r\n                var linkhash = crypto.createHash('md5').update(link).digest('hex');\r\n                redis_urlinfo_db.hgetall(linkhash,function(err, link_info){\r\n                    //4---------------------------------------------------------------------------------\r\n                    if(err)throw(err);\r\n                    if(!link_info||isEmpty(link_info)){\r\n                        logger.warn(link+' has no url info, '+linkhash+', we try to match it');\r\n                        var urlinfo = spider.wrapLink(link);\r\n                        if(urlinfo!=null)spider.spiderCore.emit('new_url_queue',urlinfo);\r\n                        else{\r\n                            logger.error(link+' can not match any driller rule, ignore it.');\r\n                            spider.getUrlQueue(callback);\r\n                        }\r\n                    }else{\r\n                        if(!link_info['trace']){\r\n                            logger.warn(link+', url info is incomplete');\r\n                            spider.getUrlQueue(callback);\r\n                        }else{\r\n                            var drillerinfo = spider.getDrillerRules(link_info['trace']);\r\n                                if(drillerinfo==null){\r\n                                    redis_urlinfo_db.del(linkhash,function(err){\r\n                                        logger.warn(link+', has dirty driller info! clean it');\r\n                                        var urlinfo = spider.wrapLink(link);\r\n                                        if(urlinfo!=null)spider.spiderCore.emit('new_url_queue',urlinfo);\r\n                                        else{\r\n                                            logger.error('Cleaned dirty driller info for '+link+', but can not match any driller rule right now, ignore it.');\r\n                                            spider.getUrlQueue(callback);\r\n                                        }\r\n                                    });\r\n                                }else{\r\n                                    var urlinfo = {\r\n                                        \"url\":link,\r\n                                        \"version\":parseInt(link_info['version']),\r\n                                        \"type\":drillerinfo['type'],\r\n                                        \"format\":drillerinfo['format'],\r\n                                        \"encoding\":drillerinfo['encoding'],\r\n                                        \"referer\":link_info['referer'],\r\n                                        \"url_pattern\":drillerinfo['url_pattern'],\r\n                                        \"urllib\":link_info['trace'],\r\n                                        \"save_page\":drillerinfo['save_page'],\r\n                                        \"cookie\":drillerinfo['cookie'],\r\n                                        \"jshandle\":drillerinfo['jshandle'],\r\n                                        \"inject_jquery\":drillerinfo['inject_jquery'],\r\n                                        \"drill_rules\":drillerinfo['drill_rules'],\r\n                                        \"drill_relation\":link_info['drill_relation'],\r\n                                        \"validation_keywords\":drillerinfo['validation_keywords']&&drillerinfo['validation_keywords']!='undefined'?drillerinfo['validation_keywords']:'',\r\n                                        \"script\":drillerinfo['script'],\r\n                                        \"navigate_rule\":drillerinfo['navigate_rule'],\r\n                                        \"stoppage\":drillerinfo['stoppage'],\r\n                                        \"start_time\":(new Date()).getTime()\r\n                                    }\r\n                                    logger.info('new url: '+link);\r\n                                    spider.spiderCore.emit('new_url_queue',urlinfo);\r\n                                    if(callback)callback(true);\r\n                                }\r\n                        }\r\n                    }\r\n                    //4-----------------------------------------------------------------------------------\r\n                });\r\n                //3---------------------------------------------------------------------------------------\r\n        });\r\n}\r\n/**\r\n * Check how many urls can be append to queue\r\n * @param spider\r\n */\r\nspider.prototype.checkQueue = function(spider){\r\n    var breakTt = false;\r\n    async.whilst(\r\n        function() {\r\n            logger.debug('Check queue, length: '+spider.queue_length);\r\n            return spider.queue_length < spider.spiderCore.settings['spider_concurrency'] && breakTt !== true;\r\n        },\r\n        function(cb) {\r\n            spider.getUrlQueue(function(bol){\r\n                if(bol===true)spider.queue_length++;\r\n                else breakTt = true;\r\n                cb();\r\n            });\r\n        },\r\n        function(err) {\r\n            if(err)logger.error('Exception in check queue.');\r\n        }\r\n    );\r\n}\r\n/**\r\n * TOP Domain,e.g: www.baidu.com  -> baidu.com\r\n * @param domain\r\n * @returns {*}\r\n * @private\r\n */\r\nspider.prototype.__getTopLevelDomain = function(domain){\r\n    var arr = domain.split('.');\r\n    if(arr.length<=2)return domain;\r\n    else return arr.slice(1).join('.');\r\n}\r\n/**\r\n * detect link which driller rule matched\r\n * @param link\r\n * @returns {string}\r\n */\r\nspider.prototype.detectLink = function(link){\r\n    var urlobj = url.parse(link);\r\n    var result = '';\r\n    var domain = this.__getTopLevelDomain(urlobj['hostname']);\r\n    if(this.driller_rules[domain]!=undefined){\r\n        var alias = this.driller_rules[domain];\r\n        for(a in alias){\r\n            if(alias.hasOwnProperty(a)){\r\n                //var url_pattern  = decodeURIComponent(alias[a]['url_pattern']);\r\n                var url_pattern  = alias[a]['url_pattern'];\r\n                var patt = new RegExp(url_pattern);\r\n                if(patt.test(link)){\r\n                    result = 'driller:'+domain+':'+a;\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return result;\r\n}\r\n/**\r\n * construct a url info\r\n * @param link\r\n * @returns {*}\r\n */\r\nspider.prototype.wrapLink = function(link){\r\n    var linkinfo = null;\r\n    var driller = this.detectLink(link);\r\n    if(driller!=''){\r\n        var driller_arr = driller.split(':');\r\n        var drillerinfo = this.driller_rules[driller_arr[1]][driller_arr[2]];\r\n        linkinfo = {\r\n            \"url\":link,\r\n            \"version\":(new Date()).getTime(),\r\n            \"type\":drillerinfo['type'],\r\n            \"format\":drillerinfo['format'],\r\n            \"encoding\":drillerinfo['encoding'],\r\n            \"referer\":\"\",\r\n            \"url_pattern\":drillerinfo['url_pattern'],\r\n            \"urllib\":'urllib:'+driller,\r\n            \"save_page\":drillerinfo['save_page'],\r\n            \"cookie\":drillerinfo['cookie'],\r\n            \"jshandle\":drillerinfo['jshandle'],\r\n            \"inject_jquery\":drillerinfo['inject_jquery'],\r\n            \"drill_rules\":drillerinfo['drill_rules'],\r\n            \"drill_relation\":'*',\r\n            \"validation_keywords\":drillerinfo['validation_keywords']&&drillerinfo['validation_keywords']!='undefined'?drillerinfo['validation_keywords']:'',\r\n            \"script\":drillerinfo['script'],\r\n            \"navigate_rule\":drillerinfo['navigate_rule'],\r\n            \"stoppage\":drillerinfo['stoppage']\r\n        }\r\n    }\r\n    return linkinfo;\r\n}\r\n/**\r\n * check retry\r\n * @param urlinfo\r\n */\r\nspider.prototype.retryCrawl = function(urlinfo){\r\n    var spider = this;\r\n    var retryLimit = 3;\r\n    if(spider.spiderCore.settings['download_retry']&&spider.spiderCore.settings['download_retry']!=undefined){\r\n        retryLimit = spider.spiderCore.settings['download_retry'];\r\n    }\r\n    var act_retry = 0;\r\n    if(urlinfo['retry'])act_retry = urlinfo['retry'];\r\n\r\n    if(act_retry<retryLimit){\r\n        urlinfo['retry'] = act_retry+1;\r\n        logger.info(util.format('Retry url: %s, time: ',urlinfo['url'],urlinfo['retry']));\r\n        spider.spiderCore.emit('new_url_queue',urlinfo);\r\n        if('crawl_retry_alert' in spider.spiderCore.spider_extend)spider.spiderCore.spider_extend.crawl_retry_alert(urlinfo);//report\r\n    }else{\r\n        spider.updateLinkState(urlinfo['url'],'crawled_failure');\r\n        logger.error(util.format('after %s reties, give up crawl %s',urlinfo['retry'],urlinfo['url']));\r\n        spider.redis_cli2.zadd('fail:'+urlinfo['urllib'],urlinfo['version'],urlinfo['url'],function(err,result){\r\n            spider.spiderCore.emit('slide_queue');\r\n        });\r\n        if('crawl_fail_alert' in spider.spiderCore.spider_extend)spider.spiderCore.spider_extend.crawl_fail_alert(urlinfo);//report\r\n    }\r\n}\r\n\r\n\r\n/**\r\n * update link state to redis db\r\n * @param link\r\n * @param state\r\n */\r\nspider.prototype.updateLinkState = function(link,state,callback){\r\n    var spider = this;\r\n    var urlhash = crypto.createHash('md5').update(link+'').digest('hex');\r\n    this.redis_cli1.hgetall(urlhash,function(err,link_info){\r\n        if(err){\r\n            logger.error('get state of link('+link+') fail: '+err);\r\n            if(callback)callback(err);\r\n            return;\r\n        }\r\n        if(link_info&&!isEmpty(link_info)){\r\n            var t_record = link_info['records'];\r\n            var records = [];\r\n            if(t_record!=''&&t_record!='[]'){\r\n                try{\r\n                    records = JSON.parse(t_record);\r\n                }catch(e){\r\n                    logger.error(t_record+' JSON parse error: '+e);\r\n                }\r\n            }\r\n            records.push(state);\r\n            async.parallel([\r\n                    function(cb){\r\n                        spider.redis_cli1.hmset(urlhash,{'records':JSON.stringify(records.length>3?records.slice(-3):records),'last':(new Date()).getTime(),'status':state},function(err,link_info){\r\n                            if(err)logger.error('update state of link('+link+') fail: '+err);\r\n                            else logger.debug('update state of link('+link+') success: '+state);\r\n                            cb(err);\r\n                        });\r\n                    },\r\n                    function(cb){\r\n                        if(state=='crawled_finish'){\r\n                            spider.redis_cli2.zrem('fail:'+link_info['trace'],link,function(err,result){\r\n                                logger.debug('remove '+link+' from fail:'+link_info['trace']);\r\n                                cb(err);\r\n                            });\r\n                        }else cb(null);\r\n                    }\r\n                ],\r\n                function(err, results){\r\n                    if(callback)callback(err);\r\n                });\r\n        }else{\r\n            var trace = spider.detectLink(link);\r\n            if(trace!=''){\r\n                trace = 'urllib:' + trace;\r\n                var urlinfo = {\r\n                    'url':link,\r\n                    'trace':trace,\r\n                    'referer':'',\r\n                    'create':(new Date()).getTime(),\r\n                    'records':JSON.stringify([]),\r\n                    'last':(new Date()).getTime(),\r\n                    'status':state\r\n                }\r\n\r\n                async.parallel([\r\n                        function(cb){\r\n                            spider.redis_cli1.hmset(urlhash,urlinfo,function(err, value){\r\n                                if (err) throw(err);\r\n                                logger.debug('save new url info: '+link);\r\n                                cb(err);\r\n                            });\r\n                        },\r\n                        function(cb){\r\n                            if(state==='crawled_finish'){\r\n                                spider.redis_cli2.zrem('fail:'+urlinfo['trace'],link,function(err,result){\r\n                                    logger.debug('remove '+link+' from fail:'+urlinfo['trace']);\r\n                                    cb(err);\r\n                                });\r\n                            }else cb(null);\r\n                        }\r\n                    ],\r\n                    function(err, results){\r\n                        if(callback)callback(err);\r\n                    });\r\n            }else {\r\n                logger.error(link+' can not match any rules, ignore updating.');\r\n                if(callback)callback(err);\r\n            }\r\n        }\r\n    });\r\n}\r\n\r\nmodule.exports = spider;\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/tools/http-echo-server.js":"/**\n * Created by cherokee on 14-6-16.\n */\nvar http = require('http');\nhttp.createServer(function (req, res) {\n    res.writeHead(200, {'Content-Type': 'application/json'});\n    res.end(JSON.stringify({\n        'IP':req.socket.remoteAddress,\n        'HEADERS':(function(headers){\n            var new_headers = {};\n            for(var x in headers){\n                if(headers.hasOwnProperty(x)){\n                    new_headers[x.toUpperCase()] = headers[x];\n                }\n            }\n            return new_headers;\n        })(req.headers)\n    }));\n}).listen(80, \"0.0.0.0\");\nconsole.log('Http Echo Server running at http://127.0.0.1:80/');","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/tools/queue-helper.js":"/**\n * Created by cherokee on 14-6-5.\n */\nvar async = require('async');\nvar myredis = require('../lib/myredis.js');\n\n////arguments parse///////////////////////////////////////////////////////////////\nvar userArgv = require('optimist')\n    .usage('Usage: $0 -i [instance name] -a [pfq|psq] -h')\n    .options('i', {\n        'alias' : 'instance',\n        'default' : 'example',\n        'describe' : 'Specify a instance',\n        'demand' : true\n    })\n    .options('a', {\n        'alias' : 'action',\n        'default' : 'crawl',\n        'describe' : 'Specify a action,\\n pfq(put fail url into url queue), \\n psq(put stuck url into url queue), \\n fdq(filter duplicated queue)',\n        'demand' : true\n    })\n    .options('h', {\n        'alias' : 'help',\n        'describe' : 'Help infomation'\n    });\n\nvar options = userArgv.argv;\nif(options['h']){userArgv.showHelp();process.exit();}\nvar settings = require('../instance/'+options['i']+'/'+'settings.json');\nvar dbtype = 'redis';\nif(settings['use_ssdb'])dbtype = 'ssdb';\n////executable function/////////////////////////////////////////////////////////////////\nvar put_fail_url_into_queue = function(){\n    myredis.createClient(\n        settings['driller_info_redis_db'][0],\n        settings['driller_info_redis_db'][1],\n        settings['driller_info_redis_db'][2],\n        dbtype,\n        function(err,di_redis_cli){\n            myredis.createClient(\n                settings['url_report_redis_db'][0],\n                settings['url_report_redis_db'][1],\n                settings['url_report_redis_db'][2],\n                dbtype,\n                function(err,redis_cli){\n                    redis_cli.zlist('fail:*',function(err,zkeys){\n                        if(err)throw err;\n                        var count = 0;\n                        async.whilst(\n                            function(){\n                                return count < zkeys.length;\n                            },\n                            function(callback){\n                                var zkey = zkeys[count++];\n                                if(zkey){\n                                    var urllib_key = zkey.replace('fail:','');\n                                    console.log('moving ',zkey);\n                                    redis_cli.zrange(zkey,0,(new Date()).getTime(),function(err,keylist){\n                                        var sub_count = 0;\n                                        async.whilst(\n                                            function(){\n                                                return sub_count < keylist.length;\n                                            },\n                                            function(cb){\n                                                var link = keylist[sub_count++];\n                                                if(link){\n                                                    di_redis_cli.rpush(urllib_key,link,function(err){\n                                                        if(err)console.error('Put ',urllib_key,' Error: ',err);\n                                                        else console.log('put ',link,' into ',urllib_key);\n                                                        cb(null);\n                                                    });\n                                                }else {\n                                                    console.error('Invalidate url');\n                                                    cb(null);\n                                                }\n                                            },\n                                            function(err){\n                                                if(err)throw err;\n                                                callback(err);\n                                            }\n                                        );\n                                    });\n                                }else {\n                                    console.error('Invalidate zkey');\n                                    callback(null);\n                                }\n                            },\n                            function(err){\n                                redis_cli.close();\n                                di_redis_cli.close();\n                            }\n                        );\n                    });\n                });\n        }\n    );\n}\n\nvar put_stuck_url_into_queue = function(){\n    myredis.createClient(\n        settings['driller_info_redis_db'][0],\n        settings['driller_info_redis_db'][1],\n        settings['driller_info_redis_db'][2],\n        dbtype,\n        function(err,di_redis_cli){\n            myredis.createClient(\n                settings['url_report_redis_db'][0],\n                settings['url_report_redis_db'][1],\n                settings['url_report_redis_db'][2],\n                dbtype,\n                function(err,redis_cli){\n                    redis_cli.zlist('stuck:*',function(err,zkeys){\n                        if(err)throw err;\n                        var count = 0;\n                        async.whilst(\n                            function(){\n                                return count < zkeys.length;\n                            },\n                            function(callback){\n                                var zkey = zkeys[count++];\n                                if(zkey){\n                                    var urllib_key = zkey.replace('stuck:','');\n                                    console.log('moving ',zkey);\n                                    redis_cli.zrange(zkey,0,(new Date()).getTime(),function(err,keylist){\n                                        var sub_count = 0;\n                                        async.whilst(\n                                            function(){\n                                                return sub_count < keylist.length;\n                                            },\n                                            function(cb){\n                                                var link = keylist[sub_count++];\n                                                if(link){\n                                                    di_redis_cli.rpush(urllib_key,link,function(err){\n                                                        if(err)console.error('Put ',urllib_key,' Error: ',err);\n                                                        else console.log('put ',link,' into ',urllib_key);\n                                                        cb(null);\n                                                    });\n                                                }else {\n                                                    console.error('Invalidate url');\n                                                    cb(null);\n                                                }\n                                            },\n                                            function(err){\n                                                if(err)throw err;\n                                                callback(err);\n                                            }\n                                        );\n                                    });\n                                }else {\n                                    console.error('Invalidate zkey');\n                                    callback(null);\n                                }\n                            },\n                            function(err){\n                                redis_cli.close();\n                                di_redis_cli.close();\n                            }\n                        );\n                    });\n                });\n        });\n}\n\nvar filter_duplicated_queue = function(){\n    myredis.createClient(\n        settings['driller_info_redis_db'][0],\n        settings['driller_info_redis_db'][1],\n        settings['driller_info_redis_db'][2],\n        dbtype,\n        function(err,redis_cli){\n            if(err)throw err;\n            redis_cli.qlist('urllib:*',function(err,zkeys){\n                if(err)throw err;\n                var count = 0;\n                async.whilst(\n                    function(){\n                        return count < zkeys.length;\n                    },\n                    function(callback){\n                        var zkey = zkeys[count++];\n                        var uniq_dict = {};\n                        console.log('checking ',zkey);\n                        if(zkey){\n                            redis_cli.llen(zkey,function(err,qsize){\n                                if(err){console.error(err);callback();}\n                                else if(!qsize||qsize<1){\n                                    console.log(zkey,' is empty');\n                                    callback();\n                                }else{\n                                    //////////////////////////////////////\n                                    var last_queue_key = false;\n                                    var t_count = 0;\n                                    var f_count = 0;\n                                    async.doWhilst(\n                                        function(cb){\n                                            redis_cli.lpop(zkey,function(err,val){\n                                                last_queue_key = val;\n                                                t_count++;\n                                                if(err){console.error(err);cb();}\n                                                else{\n                                                    if(val){\n                                                        if(uniq_dict[val]){\n                                                            console.log(zkey,' filter ',val,' ,counter: ',(++f_count),' / ',t_count);\n                                                            cb();\n                                                        }else{\n                                                            console.log(zkey,' keep ',val,' ,counter: ',f_count,' / ',t_count);\n                                                            uniq_dict[val] = true;\n                                                            redis_cli.rpush(zkey,val,function(err){\n                                                                if(err)console.error(err);\n                                                                cb();\n                                                            });\n                                                        }\n                                                    }else cb();\n                                                }\n                                            });\n                                        },\n                                        function(){return t_count<qsize&&last_queue_key;},\n                                        function(err){\n                                            callback(null);\n                                        }\n                                    );\n                                    ////////////////////////////////////////////////////\n                                }\n                            });\n                        }else {\n                            console.error('Invalidate zkey');\n                            callback(null);\n                        }\n                    },\n                    function(err){\n                        redis_cli.close();\n                    }\n                );\n            });\n        });\n}\n\n////action route/////////////////////////////////////////////////////////////////////\nswitch(options['a']){\n    case 'pfq':\n        put_fail_url_into_queue();\n        break;\n    case 'psq':\n        put_stuck_url_into_queue();\n        break;\n    case 'fdq':\n        filter_duplicated_queue();\n        break;\n    default:\n        userArgv.showHelp();\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/tools/rule-dump.js":"/**\n * Created by James on 14-2-27.\n * redis helper: dump to file, and restore from file\n */\n\nvar userArgv = require('optimist')\n    .usage('Usage: $0 -h [host name] -p [port]  -f [file prefix] -h')\n    .options('h', {\n        'alias' : 'host',\n        'default' : 'localhost',\n        'describe' : 'Specify redis hostname, e.g: localhost',\n        'demand' : true\n    })\n    .options('p', {\n        'alias' : 'port',\n        'default' : 6379,\n        'describe' : 'Specify redis port, e.g: 6379',\n        'demand' : true\n    })\n    .options('f', {\n        'alias' : 'file',\n        'default' : 'dump',\n        'describe' : 'Specify a file name'\n    })\n    .options('t', {\n        'alias' : 'type',\n        'default' : 'redis',\n        'describe' : 'Specify a DBtype: redis/ssdb'\n    })\n    .options('d', {\n        'alias' : 'db',\n        'default' : '0',\n        'describe' : 'Specify a db'\n    })\n    .options('q', {\n        'alias' : 'query',\n        'default' : 'driller:*',\n        'describe' : 'Specify a query string, e.g:driller:*'\n    })\n    .options('H', {\n        'alias' : 'help',\n        'describe' : 'Help infomation'\n    });\n\nvar options = userArgv.argv;\nif(options['H']){userArgv.showHelp();process.exit();}\n\nvar redis = require(\"../lib/myredis.js\");\nvar fs = require(\"fs\");\nvar async = require('async');\n\nvar dumpdb = function(db){\n    redis.createClient(options['h'],options['p'],db,options['t'],function(err,redis_cli)\n        {\n                redis_cli.hlist(options['q'],function(err,keyList){\n                    for(var i=0;i<keyList.length;i++){}\n                    var count = 0;\n                    if(fs.existsSync(options['f']))fs.unlinkSync(options['f']);\n                    async.whilst(\n                        function () { return count < keyList.length; },\n                        function (callback) {\n                            var key = keyList[count];\n                            console.log('dump db'+db+' '+key);\n                            redis_cli.hgetall(key,function(err,value){\n                                if(err){console.log(err);callback(err);}\n                                count++;\n                                fs.appendFile(options['f'], key+'\\n'+JSON.stringify(value)+'\\n',{'encoding':'utf8'},function(err){\n                                    if (err) throw err;\n                                    else callback();\n                                });\n                            });\n                        },\n                        function(err) {\n                            if(err){\n                                console.log('dump db'+db+' failure.'+err);\n                            }else{\n                                console.log('dump '+options['h']+':'+options['p']+' db'+db+' to '+options['f']);\n                            }\n                            redis_cli.quit();\n                        }\n                    );\n                });\n        }\n    );\n}\ndumpdb(parseInt(options['d']));","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/tools/rule-restore.js":"/**\n * Created by James on 14-2-27.\n * redis helper: dump to file, and restore from file\n */\n\nvar userArgv = require('optimist')\n    .usage('Usage: $0 -h [host name] -p [port]  -f [file prefix] -h')\n    .options('h', {\n        'alias' : 'host',\n        'default' : 'localhost',\n        'describe' : 'Specify redis hostname, e.g: localhost',\n        'demand' : true\n    })\n    .options('p', {\n        'alias' : 'port',\n        'default' : 6379,\n        'describe' : 'Specify redis port, e.g: 6379',\n        'demand' : true\n    })\n    .options('f', {\n        'alias' : 'file',\n        'default' : 'dump',\n        'describe' : 'Specify a file name , do not include suffix'\n    })\n    .options('t', {\n        'alias' : 'type',\n        'default' : 'redis',\n        'describe' : 'Specify a DBtype: redis/ssdb'\n    })\n    .options('d', {\n        'alias' : 'db',\n        'default' : '0',\n        'describe' : 'Specify a db'\n    })\n    .options('H', {\n        'alias' : 'help',\n        'describe' : 'Help infomation'\n    });\n\nvar options = userArgv.argv;\nif(options['H']){userArgv.showHelp();process.exit();}\n\nvar redis = require(\"../lib/myredis.js\");\nvar fs = require(\"fs\");\nvar lineReader = require('../lib/line_reader.js');\n\nvar restoredb = function(db){\n    redis.createClient(options['h'],options['p'],db,options['t'],function(err,redis_cli)\n    {\n        if(err)throw err;\n        var count = 0;\n        var key,value;\n        lineReader.eachLine(options['f'], function(line, last,cb) {\n            if(count++%2==0){\n                key = line;\n                if(last){\n                    redis_cli.quit();\n                    cb(false);\n                }else cb();\n            }else {\n                value = JSON.parse(line);\n                redis_cli.hmset(key,value,function(err,status){\n                    if(err)console.log(err);\n                    else console.log('restore db'+db+' '+key+' status:'+status);\n                    if(last){\n                        redis_cli.quit();\n                        cb(false);\n                    }else cb();\n                });\n            }\n        });\n    });\n}\nrestoredb(parseInt(options['d']));","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/routecontroller.js":"// map request with request handler\nexports.mapRoute = function(app) {\n\t//prefix = '/' + prefix;\n\n\tprefix_rule = '/rule';\n\tprefix_proxy = '/proxy';\n    prefix_monitor = '/monitor';\n\n\tvar prefixRuleObj = require('./controllers' + prefix_rule);\n\tvar prefixProxyObj = require('./controllers' + prefix_proxy);\n    var prefixMonitorObj = require('./controllers' + prefix_monitor);\n\n\t// index\n\tapp.get(prefix_rule, prefixRuleObj.index);\n\t\n\t// search\n\tapp.post(prefix_rule + '/search', prefixRuleObj.search);\t\n\t// add\n\tapp.get(prefix_rule + '/new', prefixRuleObj.new);\n\t// show\n\tapp.get(prefix_rule + '/:id', prefixRuleObj.show);\n\t// create\n\tapp.post(prefix_rule + '/create', prefixRuleObj.create);\n\t// edit\n\tapp.get(prefix_rule + '/:id/edit', prefixRuleObj.edit);\n\t// update\n\tapp.post(prefix_rule + '/upsert', prefixRuleObj.update);\n\t// destroy\n\tapp.del(prefix_rule + '/:id', prefixRuleObj.destroy);\n\t\n/////////////////////////////////////////////////////////////////////\n\t// Proxy index \n\tapp.get(prefix_proxy, prefixProxyObj.index);\n\t// Proxy index \n\tapp.get(prefix_proxy + '/index', prefixProxyObj.index);\t\n\t// Proxy edit \n\tapp.get(prefix_proxy + \"/new\", prefixProxyObj.new);\n\t// Proxy create \n\tapp.post(prefix_proxy + \"/create\", prefixProxyObj.create);\n\t// Proxy destroy \n\tapp.get(prefix_proxy + \"/:host/:key\", prefixProxyObj.destroy);\n\n/////////////////////////////////////////////////////////////////////////\n\n    app.get(prefix_monitor + \"/daily\", prefixMonitorObj.daily);\n    app.get(prefix_monitor + \"/linkdb\", prefixMonitorObj.linkdb);\n    app.get(prefix_monitor + \"/chart\", prefixMonitorObj.chart);\n};","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/webconfig.js":"/**\r\n * Module dependencies.\r\n */\r\n\r\nvar express = require('express');\r\nvar controller = require('./routecontroller.js');\r\nvar routes = require('./routes')\r\nvar http = require('http');\r\nvar path = require('path');\r\nvar ejs = require('ejs');\r\nvar events = require('events');\r\nvar stylus = require('stylus')\r\n\r\n// constructor\r\nvar webconfig = function(webconfigCore){\r\n\tevents.EventEmitter.call(this);\r\n\tthis.webconfigCore = webconfigCore;\r\n\tlogger = webconfigCore.settings.logger;\r\n}\r\n\r\n//////////////////////////////////\r\nDate.prototype.Format = function (fmt) {\r\n    var o = {\r\n        \"M+\": this.getMonth() + 1,\r\n        \"d+\": this.getDate(),\r\n        \"h+\": this.getHours(),\r\n        \"m+\": this.getMinutes(),\r\n        \"s+\": this.getSeconds(),\r\n        \"q+\": Math.floor((this.getMonth() + 3) / 3),\r\n        \"S\": this.getMilliseconds()\r\n    };\r\n    if (/(y+)/.test(fmt)) fmt = fmt.replace(RegExp.$1, (this.getFullYear() + \"\").substr(4 - RegExp.$1.length));\r\n    for (var k in o)\r\n        if (new RegExp(\"(\" + k + \")\").test(fmt)) fmt = fmt.replace(RegExp.$1, (RegExp.$1.length == 1) ? (o[k]) : ((\"00\" + o[k]).substr((\"\" + o[k]).length)));\r\n    return fmt;\r\n}\r\n//////////////////////////////////\r\n\r\nejs.filters.localDate = function(date,fmt) {\r\n    return date.Format(fmt);\r\n};\r\n\r\nwebconfig.prototype.launch = function(settings){\r\n\r\n\tvar app = express();\r\n\t// all environments\r\n\tapp.set('port', settings['port']);\r\n\r\n\r\n\tapp.configure(function(){\r\n\t  app.set('views', __dirname + '/views');\r\n\t  app.set('view engine', 'ejs');\r\n\t  app.use(express.favicon());\r\n//\t  app.use(express.logger('dev'));\r\n\t  //\r\n      app.use(express.cookieParser());\r\n\t  app.use(express.session({secret: '1234567890QWERTY'}));\r\n \t  //\r\n\t  app.use(express.urlencoded());\r\n\t  app.use(express.staticCache({maxObjects: 100, maxLength: 512}));\r\n\t  app.use(stylus.middleware({\r\n\t\tsrc: __dirname + '/views'\r\n\t\t, dest: __dirname + '/public'\r\n\t\t}));\r\n\t  app.use(express.static(__dirname + '/public'));\r\n\t  app.use(express.bodyParser());\r\n\t  app.use(express.methodOverride());\r\n\t  app.use(app.router);\r\n\t  app.use(express.directory(__dirname + '/public'));\r\n\t  app.use(function(req, res, next){\r\n\t    throw new Error(req.url + ' not found');\r\n\t  });\r\n\t  app.use(function(err, req, res, next) {\r\n\t    if(err)console.error(err);\r\n\t    res.send(err.message);\r\n\t  });\r\n\t});\r\n\t// development only\r\n\tif ('development' == app.get('env')) {\r\n\t\tapp.use(express.errorHandler());\r\n\t}\r\n\t\r\n        // Authenticator\r\n        //app.use(express.basicAuth('config','config123'));//for 2.x\r\n\tif(settings['config_web_auth']){\r\n\tvar basicAuth = express.basicAuth(function(username, password) {\r\n  \t\treturn (username == settings['config_web_auth'][0] && password == settings['config_web_auth'][1]);\r\n\t},'Restrict area, please identify');\t\r\n\t\r\n\tapp.all(\"*\", basicAuth);\r\n\t}\r\n\r\n        app.get('/', routes.index);\r\n\tcontroller.mapRoute(app);\r\n\r\n\tconsole.log('create server.');\r\n\thttp.createServer(app).listen(app.get('port'), function(){\r\n\t\tconsole.log('webconfig server listening on port ' + app.get('port'));\r\n\t});\r\n}\r\n////////////////////////////////////////\r\nmodule.exports = webconfig;\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/routes/index.js":"\r\n/*\r\n * GET home page.\r\n */\r\n\r\nexports.index = function(req, res){\r\n  res.render('index', { title: 'Config Home' }, function(err, stuff) {\r\n     if (!err) {\r\n        res.write(stuff);\r\n        res.end();\r\n     }\r\n  });\r\n};\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/instance/8zi/spider_extend.js":"/**\n * Created by james on 13-12-17.\n * spider extend: diy spider\n */\nrequire('../../lib/jsextend.js');\nvar util = require('util');\n\nvar spider_extend = function(spiderCore){\n    this.spiderCore = spiderCore;\n    logger = spiderCore.settings.logger;\n}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * synchronized assembly spider extender\n * @param callback\n */\n//spider_extend.prototype.assembly = function(callback){\n//    //do something initiation\n//      var self = this;\n//      self.reportdb = self.spiderCore.spider.redis_cli2;\n//      callback();\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * customize downloading\n * urlinfo<object>:{\"url\":string,\"version\":long,\"type\":\"branch|node\",\"format\":\"html|json|binary\",\"encoding\":\"auto|utf-8|gbk\",\"referer\":string,string,\"urllib\":string,\"save_page\":true|false,\"cookie\":array[object],\"jshandle\":true|false,\"inject_jquery\":true|false,\"drill_rules\":object,\"drill_relation\":object,\"validation_keywords\":array,\"script\":array,\"navigate_rule\":array,\"stoppage\":int,\"start_time\":long}\n * callback:\n * parameter 1: error\n * parameter 2: <object>:{\n            \"remote_proxy\":string,\n            \"drill_count\":int,\n            \"cookie\":array or string,\n            \"url\":string,\n            \"statusCode\":int,\n            \"origin\":object==urlinfo,\n            \"cost\":long,\n            \"content\":html string\n        }\n * if all parameter return null, means give up customize downloading, use built-in download middleware\n */\n//spider_extend.prototype.download = function(urlinfo,callback){\n//    callback(null,null);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * DIY extract, it happens after spider framework extracted data.\n * @param extracted_info\n * {\n        \"signal\":CMD_SIGNAL_CRAWL_SUCCESS,\n        \"content\":'...',\n        \"remote_proxy\":'...',\n        \"cost\":122,\n        \"extracted_data\":{\"field\":\"value\"...}\n        \"inject_jquery\":true,\n        \"js_result\":[],\n        \"drill_link\":{\"urllib_alias\":[]},\n        \"drill_count\":0,\n        \"cookie\":[],\n        \"url\":'',\n        \"status\":200,\n        \"origin\":{\n            \"url\":link,\n            \"type\":'branch/node',\n            \"referer\":'',\n            \"url_pattern\":'...',\n            \"save_page\":true,\n            \"cookie\":[],\n            \"jshandle\":true,\n            \"inject_jquery\":true,\n            \"drill_rules\":[],\n            \"script\":[],\n            \"navigate_rule\":[],\n            \"stoppage\":-1,\n            \"start_time\":1234\n        }\n    };\n */\n//spider_extend.prototype.extract = function(extracted_info,callback){\n//    callback(extracted_info);\n//}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * customizing pipeline\n * if it do nothing , comment it\n * @param extracted_info (same to extract)\n */\n//spider_extend.prototype.pipeline = function(extracted_info,callback){\n//    logger.debug('spider extender receive extracted info from '+extracted_info['url']);\n//    callback();\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * it happens crawl started\n * @param urlinfo\n */\n//spider_extend.prototype.crawl_start_alert = function(urlinfo){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'crawl:'+__getTopLevelDomain(urlinfo['url']),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report retry crawl\n * @param urlinfo:{\n            \"url\":link,\n            \"type\":'branch/node',\n            \"referer\":'',\n            \"url_pattern\":'...',\n            \"save_page\":true,\n            \"cookie\":[],\n            \"jshandle\":true,\n            \"inject_jquery\":true,\n            \"drill_rules\":[],\n            \"script\":[],\n            \"navigate_rule\":[],\n            \"stoppage\":-1,\n            \"start_time\":1234\n        }\n *\n */\n//spider_extend.prototype.crawl_retry_alert = function(urlinfo){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'retry:'+__getTopLevelDomain(urlinfo['url']),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report failed crawl\n * @param urlinfo:{\n            \"url\":link,\n            \"type\":'branch/node',\n            \"referer\":'',\n            \"url_pattern\":'...',\n            \"save_page\":true,\n            \"cookie\":[],\n            \"jshandle\":true,\n            \"inject_jquery\":true,\n            \"drill_rules\":[],\n            \"script\":[],\n            \"navigate_rule\":[],\n            \"stoppage\":-1,\n            \"start_time\":1234\n        }\n *\n */\n//spider_extend.prototype.crawl_fail_alert = function(urlinfo){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'fail:'+__getTopLevelDomain(urlinfo['url']),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report extracted data lacks of some fields\n */\n//spider_extend.prototype.data_lack_alert = function(url,fields){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'lack:'+__getTopLevelDomain(url),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report a url crawling finish\n * @param crawled_info\n */\n//spider_extend.prototype.crawl_finish_alert = function(crawled_info){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'finish:'+__getTopLevelDomain(crawled_info['url']),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report saving content\n * if it do nothing , comment it\n * @param extracted_info (same to extract)\n */\n//spider_extend.prototype.save_content_alert  = function(extracted_info){\n//    this.reportdb.hincrby('count:'+__getDateStr(),'save:'+__getTopLevelDomain(extracted_info['url']),1);\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * report no queue\n */\n//spider_extend.prototype.no_queue_alert = function(){\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/**\n * TOP Domain,e.g: http://www.baidu.com/sdfdsfdsf  -> baidu.com\n * @param domain\n * @returns {*}\n * @private\n */\n//var __getTopLevelDomain = function(link){\n//    var urlobj = url.parse(link);\n//    var domain = urlobj['hostname'];\n//    var arr = domain.split('.');\n//    if(arr.length<=2)return domain;\n//    else return arr.slice(1).join('.');\n//}\n/**\n * get date string\n * @returns {string} 20140928\n * @private\n */\n//var __getDateStr = function(){\n//    var d = new Date();\n//    return ''+ d.getFullYear() + (d.getMonth()>9?d.getMonth()+1:'0'+(d.getMonth()+1)) + (d.getDate()>9?d.getDate():'0'+d.getDate());\n//}\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\nmodule.exports = spider_extend;","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/phantomjs/phantomjs-bridge.js":"/**\r\n * Created by james on 13-11-22.\r\n * phantom js bridge\r\n */\r\n\r\nvar system = require('system');\r\nvar page = require('webpage').create();\r\n\r\n//command signal defined\r\nvar CMD_SIGNAL_CRAWL_SUCCESS = 1;\r\nvar CMD_SIGNAL_CRAWL_FAIL = 3;\r\nvar CMD_SIGNAL_NAVIGATE_EXCEPTION = 2;\r\nvar retryTimer = null;\r\n\r\n////phantomjs client identify\r\nvar pid = system.pid;\r\n////caller interactive////////////////////////////////////////////////////////////////////////\r\nvar sendToCaller = function(msg){\r\n    system.stdout.writeLine(JSON.stringify(msg)+'#^_^#');\r\n}\r\n////debugtofile//////////////////////////////////////////////////////////////////////////////\r\nvar debug2file = function(msg){\r\n    var fs  = require(\"fs\");\r\n    var ipath = origin_urlinfo['ipath'];\r\n    fs.write(ipath+'/phantomjs-debug.log',(new Date())+'==>'+JSON.stringify(msg)+'\\n','a');\r\n}\r\n////user agent////////////////////////////////////////////////////////////////////////////////\r\npage.settings.userAgent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.57 Safari/537.36';\r\npage.viewportSize = { width: 1280, height: 5000 };\r\n////argv//////////////////////////////////////////////////////////////////////////////////////////\r\nvar drill_count = 0;\r\nif(system.args.length<2)phantom.exit();\r\ntry{\r\nvar origin_urlinfo = JSON.parse(system.args[1]);\r\n}catch(e){\r\n    sendToCaller({'signal':CMD_SIGNAL_NAVIGATE_EXCEPTION,'message':'js parse fail',\"message\":e,'jsonstr':system.args[1]});\r\n}\r\n\r\n////set cookie///////////////////////////////////////////////////////////////////////////////////\r\nfor(var i=0;i<origin_urlinfo['cookie'].length;i++){\r\n    try{\r\n        phantom.addCookie(origin_urlinfo['cookie'][i]);\r\n    }catch(e){\r\n        //pass\r\n    }\r\n}\r\n\r\n////page event////////////////////////////////////////////////////////////////////////////////////\r\npage.onResourceRequested = function (req) {\r\n    //you can ignore css here\r\n};\r\n\r\npage.onResourceReceived = function (res) {\r\n    if (res.stage === 'start') {\r\n    }\r\n    else if (res.stage === 'end') {\r\n        if(res.url===page.url){\r\n            page.status = res.status;\r\n            for(var s=0;s<res.headers.length;s++){\r\n                if(res.headers[s]['name']==='remoteproxy'){\r\n                    page.remoteProxy = res.headers[s]['value'];\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n        if(page.url===\"about:blank\"){\r\n            page.status = res.status;\r\n        }\r\n    }\r\n};\r\n\r\npage.onInitialized = function() {\r\n    //nothing\r\n};\r\n\r\npage.onUrlChanged = function(targetUrl) {\r\n    //pass\r\n};\r\n\r\npage.onResourceError = function(resourceError) {\r\n    if(resourceError.url===page.url){\r\n        sendToCaller({\r\n            'signal':CMD_SIGNAL_CRAWL_FAIL,\r\n            'message':'Unable to load resource',\r\n            \"url\":resourceError.url,\r\n            \"errorCode\":resourceError.errorCode,\r\n            \"description\":resourceError.errorString\r\n        });\r\n    }\r\n};\r\n\r\npage.onLoadStarted  = function(status) {\r\n    page.startTime = new Date();\r\n    page.status = null;\r\n    if(retryTimer)clearTimeout(retryTimer);\r\n};\r\n\r\npage.onLoadFinished = function(status) {\r\n    if (status !== 'success') {\r\n        sendToCaller({'signal':CMD_SIGNAL_CRAWL_FAIL,'message':'Open page failed',\"url\":page.url});\r\n    } else {\r\n        page.endTime = new Date();\r\n        workAfterLoadFinish(0,0);\r\n    }\r\n\r\n};\r\n\r\npage.onNavigationRequested = function(url, type, willNavigate, main) {\r\n    page.customHeaders = {\r\n        \"client_pid\": pid,\r\n        \"page\": url\r\n    };\r\n}\r\n\r\nvar workAfterLoadFinish = function(drill_retry,navigateretry){\r\n    var injected = false;\r\n    if(origin_urlinfo['inject_jquery']&&(drill_retry+navigateretry)==0){\r\n        injected = page.injectJs(\"jquery-1.10.2.min.js\");\r\n    }\r\n/*\r\n    var point = page.evaluate(function(rules){\r\n        var bt = document.querySelector('ul.tb-tabbar li:nth-child(2) a.tb-tab-anchor');\r\n        $('ul.tb-tabbar li:nth-child(2) a.tb-tab-anchor').click();\r\n        return true;\r\n    },origin_urlinfo['drill_rules']);\r\n*/\r\n    var js_result = [];\r\n    if(origin_urlinfo['script'].length>0){\r\n        var script = drill_count<origin_urlinfo['script'].length?origin_urlinfo['script'][drill_count]:origin_urlinfo['script'][origin_urlinfo['script'].length-1];\r\n        if(script)js_result = jsExec(script);\r\n    }\r\n\r\n    var drill_link = [];\r\n    if(origin_urlinfo['drill_rules'].length>0){\r\n        var drill_link = page.evaluate(function(rules){\r\n            var jsexec_result = [];\r\n            for(var i=0;i<rules.length;i++){\r\n                var doms = document.querySelectorAll(rules[i]);\r\n                for(var x=0;x<doms.length;x++){\r\n                    if(doms[x].hasAttribute('href'))jsexec_result.push(doms[x].getAttribute('href'));\r\n                    else if(doms[x].hasAttribute('src'))jsexec_result.push(doms[x].getAttribute('src'));\r\n                }\r\n            }\r\n            return jsexec_result;\r\n        },origin_urlinfo['drill_rules']);\r\n        if(drill_link==undefined)drill_link=[];\r\n    }\r\n\r\n\r\n    if(drill_link.length<1&&drill_retry<30){\r\n        retryTimer = setTimeout(function(){workAfterLoadFinish(++drill_retry,navigateretry);},200);\r\n        return;\r\n    }else{\r\n        if(retryTimer)clearTimeout(retryTimer);\r\n    }\r\n\r\n    var result = {\r\n        \"signal\":CMD_SIGNAL_CRAWL_SUCCESS,\r\n        \"content\":page.content,//origin_urlinfo['type']===\"node\"?page.content:'',\r\n        \"remote_proxy\":page.remoteProxy,\r\n        \"cost\":page.endTime-page.startTime,\r\n        \"inject_jquery\":injected,\r\n        \"js_result\":js_result,\r\n        \"drill_link\":drill_link,\r\n        \"drill_count\":drill_count,\r\n        \"cookie\":page.cookies,\r\n        \"url\":page.url,\r\n        \"statusCode\":page.status,\r\n        \"origin\":origin_urlinfo\r\n    };\r\n\r\n    if(drill_count<origin_urlinfo['stoppage']-1&&origin_urlinfo['navigate_rule'].length>0&&origin_urlinfo['navigate_rule'][0]!=''){\r\n        var navigate_rule = drill_count<origin_urlinfo['navigate_rule'].length?origin_urlinfo['navigate_rule'][drill_count]:origin_urlinfo['navigate_rule'][origin_urlinfo['navigate_rule'].length-1];\r\n        //page.injectJs(\"webpatch.js\");\r\n        var button = page.evaluate(function(navigate_rule) {\r\n            var tbt = document.querySelector(navigate_rule);\r\n            return tbt;\r\n        },navigate_rule);\r\n\r\n        if(button.offsetLeft==undefined&&navigateretry<30){\r\n            retryTimer = setTimeout(function(){workAfterLoadFinish(drill_retry,++navigateretry);},200);\r\n            return;\r\n        }else{\r\n            if(retryTimer)clearTimeout(retryTimer);\r\n            sendToCaller(result);\r\n\r\n            page_test_action();\r\n\r\n            drill_count++;\r\n//            var fs = require('fs');\r\n//            var ipath = origin_urlinfo['ipath'];\r\n//            fs.write(ipath+'/debug-info'+drill_count+'.txt',JSON.stringify(button),'w');\r\n        }\r\n\r\n        if(!button)sendToCaller({'signal':CMD_SIGNAL_NAVIGATE_EXCEPTION,'message':'navigate fail',\"url\":page.url});\r\n        clickbutton(button.offsetLeft+1, button.offsetTop+1,500,0);\r\n    }else{\r\n        page_test_action();\r\n        sendToCaller(result);\r\n        phantom.exit();\r\n    }\r\n}\r\n\r\nvar page_test_action = function(){\r\n    if(origin_urlinfo['test']!=undefined){\r\n        var fs = require('fs');\r\n        var ipath = origin_urlinfo['ipath'];\r\n        page.render(ipath+'/debug-page'+drill_count+'.png');\r\n        fs.write(ipath+'/debug-browser-page'+drill_count+'.html',page.content,'w');\r\n    }\r\n}\r\n\r\nvar clickbutton = function(x,y,repeat,retry){\r\n    page.sendEvent('click',x,y);\r\n    if(retry<10){\r\n        if(repeat>0){\r\n            setTimeout(function(){clickbutton(x,y,repeat,++retry)},repeat);\r\n        }\r\n    }else{\r\n        if(retryTimer)clearTimeout(retryTimer);\r\n        sendToCaller({'signal':CMD_SIGNAL_NAVIGATE_EXCEPTION,'message':'navigate fail',\"url\":page.url});\r\n    }\r\n}\r\n\r\nvar jsExec= function(commad){\r\n    var xr = page.evaluate(function(commad){\r\n        var jsexec_result = [];\r\n        commad = 'try{'+commad+'}catch(e){}';\r\n        eval(commad);\r\n        return jsexec_result;\r\n    },commad);\r\n    return xr;\r\n}\r\n\r\n////act//////////////////////////////////////////////////////////////////////////////////////\r\npage.open(origin_urlinfo['url'], function (status) {});\r\n/*\r\nvar url = 'http://ju.taobao.com/?spm=1.6659421.754904973.2.ALtBmk';\r\nvar script = \"jsexec_result = $.makeArray($('.category li a span').text())\";\r\nvar urlinfo = {\"url\":url,\"type\":\"branch\",\"referer\":\"http://www.taobao.com\",\"jshandle\":true,\"inject_jquery\":true,\"script\":script,\"navigate_rules\":[]}\r\nopenUrl(urlinfo);\r\n*/\r\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/lib/phantomjs/webpatch.js":"/**\r\n * Created by james on 13-11-27.\r\n * web patch\r\n */\r\nif (window._phantom) {\r\n    // Patch since PhantomJS does not implement click() on HTMLElement. In some\r\n    // cases we need to execute the native click on an element. However, jQuery's\r\n    // $.fn.click() does not dispatch to the native function on <a> elements, so we\r\n    // can't use it in our implementations: $el[0].click() to correctly dispatch.\r\n    if (!HTMLElement.prototype.click) {\r\n        HTMLElement.prototype.click = function() {\r\n            var ev = document.createEvent('MouseEvent');\r\n            ev.initMouseEvent(\r\n                'click',\r\n                /*bubble*/true, /*cancelable*/true,\r\n                window, null,\r\n                0, 0, 0, 0, /*coordinates*/\r\n                false, false, false, false, /*modifier keys*/\r\n                0/*button=left*/, null\r\n            );\r\n            this.dispatchEvent(ev);\r\n        };\r\n    }\r\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/controllers/monitor.js":"/**\r\n * Created by malcolm on 1/9/14.\r\n */\r\n\r\nvar myredis = require('../../lib/myredis.js');\r\nvar async = require('async');\r\nvar ruledb = null;\r\nvar infodb = null;\r\nvar reportdb = null;\r\n\r\nvar dbtype = 'redis';\r\nif(global.settings['use_ssdb'])dbtype = 'ssdb';\r\n\r\nmyredis.createClient(\r\n    global.settings['driller_info_redis_db'][0],\r\n    global.settings['driller_info_redis_db'][1],\r\n    global.settings['driller_info_redis_db'][2],\r\n    dbtype,\r\n    function(err,cli){\r\n        ruledb = cli;\r\n    });\r\n\r\n\r\nmyredis.createClient(\r\n    global.settings['url_info_redis_db'][0],\r\n    global.settings['url_info_redis_db'][1],\r\n    global.settings['url_info_redis_db'][2],\r\n    dbtype,\r\n    function(err,cli){\r\n        infodb = cli;\r\n    });\r\n\r\n\r\nmyredis.createClient(\r\n    global.settings['url_report_redis_db'][0],\r\n    global.settings['url_report_redis_db'][1],\r\n    global.settings['url_report_redis_db'][2],\r\n    dbtype,\r\n    function(err,cli){\r\n        reportdb = cli;\r\n    });\r\n\r\n/**\r\n * get date string\r\n * @returns {string} 20140928\r\n * @private\r\n */\r\nvar __getDateStr = function(){\r\n    var d = new Date();\r\n    return ''+ d.getFullYear() + (d.getMonth()>8?d.getMonth()+1:'0'+(d.getMonth()+1)) + (d.getDate()>9?d.getDate():'0'+d.getDate());\r\n}\r\n\r\nexports.daily = function(req, res) {\r\n    var date   = req.query['date'];\r\n    if(!date)date = __getDateStr();\r\n    var result = {};\r\n    var total = {};\r\n\r\n    reportdb.hgetall('count:'+date,function(err,hashes){\r\n        for(var i in hashes){\r\n            if(hashes.hasOwnProperty(i)){\r\n                var spilited = i.split(':');\r\n                var colname = spilited[0];\r\n                var domain = spilited[1];\r\n                if(!result[domain])result[domain] = {};\r\n                result[domain][colname] = hashes[i];\r\n                if(!total[colname])total[colname] = parseInt(hashes[i]);\r\n                else total[colname] += parseInt(hashes[i]);\r\n            }\r\n        }\r\n        res.render('monitor/daily', {'result':result,'date':date,'total':total});\r\n    });\r\n};\r\n\r\nexports.linkdb = function(req, res) {\r\n    var total_linkcount = 0;\r\n    var linkcount = {};\r\n    var scheduledcount = 0;\r\n    var rulelastchanged = 0;\r\n    var linkinfodbsize = 0;\r\n\r\n    async.series([\r\n        function(callback){\r\n            ruledb.keys('urllib:driller:*',function(err,keys){\r\n                if(!err&&keys){\r\n                    var c = 0;\r\n                    async.whilst(function(){\r\n                        return c<keys.length;\r\n                    },function(cb){\r\n                        var itm = keys[c++];\r\n                        ruledb.llen(itm,function(err,size){\r\n                            if(!err&&size){\r\n                                linkcount[itm] = size;\r\n                                total_linkcount += size;\r\n                                cb();\r\n                            }else cb(err);\r\n                        });\r\n                    },function(err){\r\n                        callback();\r\n                    });\r\n                }else callback()\r\n            });\r\n        },\r\n        function(callback){\r\n            ruledb.llen('queue:scheduled:all',function(err,size){\r\n                if(!err&&size)scheduledcount = size;\r\n                callback();\r\n            });\r\n        },\r\n        function(callback){\r\n            ruledb.get('updated:driller:rule',function(err,val){\r\n                if(!err&&val)rulelastchanged = val;\r\n                callback();\r\n            });\r\n        },\r\n        function(callback){\r\n            infodb.dbsize(function(err,size){\r\n                if(!err&&size)linkinfodbsize = size;\r\n                callback();\r\n            });\r\n        }\r\n    ],function(err){\r\n        res.render('monitor/linkdb', {'total_linkcount':total_linkcount,'linkcount':linkcount,'scheduledcount':scheduledcount,'rulelastchanged':rulelastchanged,'linkinfodbsize':linkinfodbsize});\r\n    })\r\n};\r\n\r\nexports.chart = function(req, res) {\r\n    var domain   = req.query['domain'];\r\n    var sdays   = req.query['days']||'30';\r\n    var days = parseInt(sdays);\r\n\r\n    var nd = new Date();\r\n    var nl = nd.getTime();\r\n    var date_arr = [];\r\n    var crawl_arr = [];\r\n    var retry_arr = [];\r\n    var fail_arr = [];\r\n    var lack_arr = [];\r\n    var save_arr = [];\r\n    var finish_arr = [];\r\n\r\n    var index = days;\r\n    async.whilst(\r\n        function(){\r\n            return index >= 0;\r\n        },\r\n        function(callback){\r\n            var td = new Date(nl-86400000*index--);\r\n            var dstr = '';\r\n            dstr += td.getFullYear();\r\n            var month = td.getMonth()+1;\r\n            if(month<10)dstr += '0' + month;\r\n            else dstr += month;\r\n            if(td.getDate()<10)dstr += '0' + td.getDate();\r\n            else dstr += td.getDate();\r\n            date_arr.push(month+'-'+td.getDate());\r\n            reportdb.hgetall('count:'+dstr,function(err,hashes){\r\n                crawl_arr.push(hashes['crawl:'+domain]?parseInt(hashes['crawl:'+domain]):0);\r\n                retry_arr.push(hashes['retry:'+domain]?parseInt(hashes['retry:'+domain]):0);\r\n                fail_arr.push(hashes['fail:'+domain]?parseInt(hashes['fail:'+domain]):0);\r\n                lack_arr.push(hashes['lack:'+domain]?parseInt(hashes['lack:'+domain]):0);\r\n                save_arr.push(hashes['save:'+domain]?parseInt(hashes['save:'+domain]):0);\r\n                finish_arr.push(hashes['finish:'+domain]?parseInt(hashes['finish:'+domain]):0);\r\n                callback();\r\n            });\r\n        },\r\n        function(err){\r\n            res.render('monitor/chart',{'domain':domain,'days':days,'date_arr':date_arr,'crawl_arr':crawl_arr,'retry_arr':retry_arr,'fail_arr':fail_arr,'lack_arr':lack_arr,'save_arr':save_arr,'finish_arr':finish_arr});\r\n        }\r\n    );\r\n}","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/controllers/proxy.js":"var proxyManager = require('../models/proxyManagement.js');\n\nvar proxyList = [];\n\nvar template =  {\n        key:'',\n        address: '',\n        authorize: '',\n        group: ''};\n\nPROXY_P_PREFIX = 'proxy:public:available:';\nPROXY_P_KEY1S = 'proxy:public:available:1s';\nPROXY_P_KEY3S = 'proxy:public:available:3s';\nPROXY_P_KEY5S = 'proxy:public:available:5s';\nPROXY_P_KEY8S = 'proxy:public:available:8s';\nPROXY_P_KEY12S = 'proxy:public:available:12s';\nPROXY_P_KEY20S = 'proxy:public:available:20s';\n\nPROXY_V_PREFIX = 'proxy:vip:available:';\nPROXY_V_KEY1S = 'proxy:vip:available:1s';\nPROXY_V_KEY3S = 'proxy:vip:available:3s';\nPROXY_V_KEY8S = 'proxy:vip:available:8s';\nPROXY_V_KEY15S = 'proxy:vip:available:15s';\n\n// index displaying all available proxy list\nexports.index = function(req, res) {\n   \n   proxyManager.getProxyList(function(err, result){\n     //proxyList = result;\n     proxyList = [];\n//        console.log(\"proxy list:\", result);\n       res.render('proxy/index', {title : 'Available Proxy List', proxyList:result});\n   });  \n};\n\n// display new proxy form\nexports.new = function(req, res) {\n    var filePath = require('path').normalize(__dirname + \"/../public/proxy/new.html\");\n    res.sendfile(filePath);\n};\n\nexports.create = function(req, res) {\n//    console.log(\"address:\", req.body.address);\n//    console.log(\"authorize:\", req.body.authorize);\n//    console.log(\"group:\", req.body.group);\n\n    var group = req.body.group;\n    var key;\n    if(group[0] === 'p'){\n      key = PROXY_P_PREFIX + group.substring(1);\n    }else{\n      key = PROXY_V_PREFIX + group.substring(1);\n    }\n//    console.log(\"key:\", key);\n\n    template['address'] = req.body.address;\n    template['authorize'] = req.body.authorize;\n    template['group'] = req.body.group;\n    template['key'] = key;\n\n    proxyManager.create(key, template['address'], function(err, result){\n        if(!err) {\n            \n         } \n    });\n    res.redirect('proxy');\n};\n\n// delete a widget\nexports.destroy = function(req,res) {\n  var host = req.params.host;\n  var key = req.params.key;\n\n//  console.log(host, key);\n  proxyManager.destroy(key, host, function(err, result){\n\n//        console.log('Host', host, 'deleted.');\n          \n        if(!err) {\n           \n                //console.log(\"list:\", result);\n               \n\n         }  \n         res.redirect('proxy'); \n  });\n\n};","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/models/proxyManagement.js":"\n// Proxy Management model\n\nvar myredis = require('../../lib/myredis.js');\nvar async = require('async');\n//var settings = require('../../instance/webconfig/settings.json');\n\nvar settings = global.settings;\n\nvar dbtype = 'redis';\nif(settings['use_ssdb'])dbtype = 'ssdb';\nvar client;\nmyredis.createClient(\n    settings['proxy_info_redis_db'][0],\n    settings['proxy_info_redis_db'][1],\n    settings['proxy_info_redis_db'][2],\n    dbtype,\n    function(err,cli){\n        client = cli;\n    });\n\n// available proxy list\nPROXY_P_PREFIX = 'proxy:public:available:';\nPROXY_P_KEY1S = 'proxy:public:available:1s';\nPROXY_P_KEY3S = 'proxy:public:available:3s';\nPROXY_P_KEY5S = 'proxy:public:available:5s';\nPROXY_P_KEY8S = 'proxy:public:available:8s';\nPROXY_P_KEY12S = 'proxy:public:available:12s';\nPROXY_P_KEY20S = 'proxy:public:available:20s';\n\nPROXY_V_KEY1S = 'proxy:vip:available:1s';\nPROXY_V_KEY3S = 'proxy:vip:available:3s';\nPROXY_V_KEY8S = 'proxy:vip:available:8s';\nPROXY_V_KEY15S = 'proxy:vip:available:15s';\n\nPROXY_KEYS = [PROXY_P_KEY1S,PROXY_P_KEY3S,PROXY_P_KEY5S,PROXY_P_KEY8S,PROXY_P_KEY12S,PROXY_P_KEY20S,\n\t\t\tPROXY_V_KEY1S,PROXY_V_KEY3S, PROXY_V_KEY8S, PROXY_V_KEY15S, ''];\n\nvar proxyList = [];\n\nvar proxyManagement = {\n\t\n\t// get all available proxy by their response time\n\tgetProxyList: function(fn){\n\t\tproxyList = [];\n\n\t\tvar self = this;\n\t\tvar keys = [];\n\t\tvar callFunctions = new Array();\n\n\t\tPROXY_KEYS.forEach(function(entry){\n\t\t\tcallFunctions.push(self.proxyByResponse(entry));\n\t\t});\n\n\t\tvar proxy = {};\n\t\tasync.series(\n\t\t\tcallFunctions,\n\t\t\tfunction(err, result){\n\t\t\t\tif(err) {\n\t\t\t\t\tconsole.error(err);\n\t\t\t\t\treturn fn(err);\n\t\t\t\t}\n//\t\t\t\tconsole.log(\"proxyList:\", proxyList);\n\n\t\t\treturn fn(err, proxyList);\n\t\t});\n\t},\n\n\t//\n\tproxyByResponse: function(member) {\n\t\treturn function(callback) {\n\t\t\tclient.lrange(member, 0, -1, function(err, obj) {\n\t\t\t\tcallback(err,obj);\n\t\t\t\t\n\t\t\t\tvar proxy = {};\n\t\t\t\tproxy.key = member;\n\t\t\t\tproxy.list = obj;\n\t\t\t\tobj = proxy;\n\t\t\t\tproxyList.push(proxy);\n\t\t\t\t\n\t\t\t});\n\t\t};\n\t},\n\n\t// create new proxy\n\tcreate: function(key, proxy, fn){\n\t\tclient.rpush(key, proxy, function(err, result){\n\t\t\tif(err){\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n//\t\t\tconsole.log(\"New proxy \", key, \" was created.\");\n\t\t\treturn fn(err, result);\n\t\t});\n\t},\n\n\t// delete proxy\n\tdestroy: function(key, proxy, fn){\n\t\tclient.lrem(key, 0, proxy, function(err, result){\n\t\t\tif(err){\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n//\t\t\tconsole.log(\"proxy \", key, \" was deleted.\");\n\t\t\treturn fn(err, result);\n\t\t});\n\t}\n}\n\nmodule.exports = proxyManagement;","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/controllers/rule.js":"var rule = require('../models/drillingRule.js');\n\n//default\nvar template =  {\n        'domain': '',\n        'url_pattern': '',\n        'alias': '',\n        'id_parameter': [],\n        'encoding': 'auto',\n        'type': 'node', //branch or node\n        'save_page': true,\n        'format': 'html',//html or json or binary\n        'jshandle': false,\n        'extract_rule':{\n            'category':'crawled',\n            'rule':{\n                'title':{'base':'content','mode':'css','expression':'title','pick':'text','index':1}\n            }\n        },\n        'cookie': [],\n        'inject_jquery': false,\n        'load_img': false,\n        'drill_rules': [],\n        'drill_relation': {\n            'base':'content','mode':'css','expression':'title','pick':'text','index':1\n        },\n        'validation_keywords': [],\n        'script': [],\n        'navigate_rule': [],\n        'stoppage': -1,\n        'priority': 1,\n        'weight': 10,\n        'schedule_interval': 86400,\n        'active': true,\n        'seed': [],//[]\n        'schedule_rule':'FIFO',// FIFO  or LIFO\n        'use_proxy':false\n};\n\nvar rules = [];\n\n// index displaying all the drilling rules\nexports.index = function(req, res) {\n\n  //req.session.searchBox = \"\";\n\n  if(req.session.list == null){\n    req.session.searchBox = \"\";\n     rule.getDrillingRules(function(err, result){\n         rules = result; \n         req.session.list = rules;\n         var totalPage = result.length / 15;\n         if(totalPage > 0) {            \n              rules = result.slice(0, 15);\n         }\n         res.render('rule/index', {title : 'Drilling rule', session:req.session, totalPage:totalPage});\n     });     \n      \n  }else{\n      //req.session.searchBox = domain;\n      res.render('rule/index', {title : 'Drilling rule', session:req.session});\n  }\n \n};\n\n// search\nexports.search = function(req, res) {\n\n    var domain = req.body.domain;\n    req.session.searchBox = domain;\n//    console.log('search:', domain);\n    rule.getRulesByCondition(domain,function(err, result){\n       rules = result; \n       req.session.list = rules;\n       res.render('rule/index', {title : 'Drilling rule', session:req.session});\n   });  \n};\n\n// display new rule form\nexports.new = function(req, res) {\n    var filePath = require('path').normalize(__dirname + \"/../public/rule/new.html\");\n    res.sendfile(filePath);\n\n    //var filePath = require('path').normalize(__dirname + \"/../public/rule/added.html\");\n    //res.render('rule/new', {title : 'New rule'});  \n};\n\n// add a rule, ****not use****\nexports.create = function(req, res) {\n  // get key and rule from form\n    var jsonstr = req.body.jsondata;\n    var jsonobj = JSON.parse(jsonstr);\n    var key = 'driller:' + jsonobj['domain'] + ':' + jsonobj['alias'];\n\n//    console.log(\"key\", key);\n    //console.log(\"url:\", urlencode(req.body.url_pattern));\n\n    rule.create(key, jsonobj, function(err, result){\n        if(!err) {\n\n        }\n    });\n\n    res.redirect('rule');\n};\n\n// show a specific rule\nexports.show = function(req, res) {\n  var id = req.params.id;\n  rule.displayOne(id, function(err, obj){\n    /*\n      if(obj)   \n          res.send('There is no rule with id of ' + req.params.id);\n      else*/\n          res.render('rule/show', {title : 'Show Rule', rule : obj});\n  });\n};\n\n// delete a widget\nexports.destroy = function(req,res) {\n   var id = req.params.id;\n//   console.log(\"destroy id:\", id);\n   rule.destroy(id, function(err, obj){\n      if(!err){\n//          console.log('Rule', req.params.id, 'deleted.');\n          rule.getDrillingRules(function(err, result){\n          rules = result; \n          //res.render('rule/index', {title : 'Drilling rule', rules:result});\n          res.redirect('rule');\n      });\n    }\n   }); \n};\n\n// display edit form\nexports.edit = function(req, res) {\n  var id = req.params.id;\n//  console.log(\"id:\", id);\n   rule.displayOne(id, function(err, obj){\n      if(obj){\n//        obj['id'] = id;\n          var dataobj = template;\n          var numberPattern = new RegExp(\"^\\-?[0-9]+$\");\n          for(i in obj){\n              if(obj.hasOwnProperty(i)){\n                  if(typeof(obj[i])==='string'&&(obj[i].charAt(0)==='{'||obj[i].charAt(0)==='[')){\n                      dataobj[i] = JSON.parse(obj[i]);\n                  }else if(numberPattern.test(obj[i])){\n                      dataobj[i] = parseInt(obj[i]);\n                  }else if(obj[i]==='true'){\n                      dataobj[i] = true;\n                  }else if(obj[i]==='false'){\n                      dataobj[i] = false;\n                  }else dataobj[i] = obj[i];\n              }\n          }\n        res.render('rule/edit', {title : 'Edit rule', rule:dataobj});\n      }else{\n        res.render('rule/edit', {title : 'Edit rule', rule:template});        \n      }\n   });\n};\n\n// upsert a rule\nexports.update = function(req,res) {\n    var jsonstr = req.body.jsondata;\n    var jsonobj = JSON.parse(jsonstr);\n    var key = 'driller:' + jsonobj['domain'] + ':' + jsonobj['alias'];\n\n    //console.log(\"url:\", urlencode(req.body.url_pattern));\n//    console.log(\"edit update:\", req.body.drill_rules);\n\n    //req.session.searchBox = req.body.domain;\n\n    var dataobj = {};\n    for(i in jsonobj){\n        if(jsonobj.hasOwnProperty(i)){\n            if(typeof(jsonobj[i])==='object')dataobj[i] = JSON.stringify(jsonobj[i]);\n            else{\n                dataobj[i] = jsonobj[i];}\n        }\n    }\n\n   rule.update(key, dataobj, function(err, result){\n      if(!err){\n            /*         \n          rule.getDrillingRules(function(err, result){\n            rules = result; \n            req.session.list = rules;\n            //res.render('rule/index', {title : 'Drilling rule', rules:result});\n//            console.log('Rule', id, 'updated.');\n            res.redirect('rule');\n      });\n*/\n    rule.getRulesByCondition(req.session.searchBox,function(err, result){\n       rules = result; \n       req.session.list = rules;\n       res.render('rule/index', {title : 'Drilling rule', session:req.session});\n   }); \n\n    }\n   });  \n};\n","/home/travis/build/npmtest/node-npmtest-neocrawler/node_modules/neocrawler/webconfig/models/drillingRule.js":"\n// Drilling rule model\n\nvar myredis = require('../../lib/myredis.js');\nvar async = require('async');\n//var settings = require('../../instance/webconfig/settings.json');\n\nvar settings = global.settings;\n\nvar dbtype = 'redis';\nif(settings['use_ssdb'])dbtype = 'ssdb';\nvar client;\n\nmyredis.createClient(\n    settings['driller_info_redis_db'][0],\n    settings['driller_info_redis_db'][1],\n    settings['driller_info_redis_db'][2],\n    dbtype,\n    function(err,cli){\n        client = cli;\n    });\n\nvar UPDATED_TIME = \"updated:driller:rule\";\n\nvar drillingRule = {\n\t\n\t// get all drilling rules\n\tgetDrillingRules: function(fn){\n\n\t\tvar self = this;\n\t\tvar keys = [];\n\t\t// retrieve all of keys that match rule*\n\t\tclient.hlist('driller*', function(err, keys){\n\t\t\tif(err){\n\t\t\t\t\tconsole.error('ERROR:', err);\n\t\t\t\t}else{\n//\t\t\t\t\tconsole.log(\"keys : \", keys);\n\n\t\t\t\t\tvar callFunctions = new Array();\n\n\n\t\t\t\t\tvar rules = [];\n\t\t\t\t\tfor(k in keys){\n\t\t\t\t\t\tcallFunctions.push(self.makeCallbackFunc(keys[k]));\n\t\t\t\t\t}\n\t\t\t\t\tasync.series(\n\t\t\t\t\t\tcallFunctions,\n\t\t\t\t\t\tfunction(err, result){\n\t\t\t\t\t\t\tif(err) {\n\t\t\t\t\t\t\t\tconsole.error(err);\n\t\t\t\t\t\t\t\treturn fn(err);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn fn(err, result);\n\t\t\t\t\t});\n\n\t\t\t\t}\n\t\t\t\n\t\t});\n\n\t},\n\n\t// get specific rule \n\tmakeCallbackFunc: function(member) {\n\t\treturn function(callback) {\n\t\t\tclient.hgetall(member, function(err, obj) {\n\t\t\t\t//console.log(\"member:\", obj)\n\t\t\t\tobj['id'] = member;\n\t\t\t\tcallback(err,obj);\n\t\t\t});\n\t\t};\n\t},\n\n\t// get all drilling rules\n\tgetRulesByCondition: function(condition, fn){\n\n\t\tvar self = this;\n\t\tvar keys = [];\n\t\tvar regex = 'driller:' + condition + '*';\n\t\t// retrieve all of keys that match rule*\n\t\tclient.hlist(regex, function(err, keys){\n\t\t\tif(err){\n\t\t\t\t\tconsole.error('ERROR:', err);\n\t\t\t\t}else{\n\n\t\t\t\t\tvar callFunctions = new Array();\n\n\n\t\t\t\t\tvar rules = [];\n\t\t\t\t\tfor(k in keys){\n\t\t\t\t\t\tcallFunctions.push(self.makeCallbackFunc(keys[k]));\n\t\t\t\t\t}\n\t\t\t\t\tasync.series(\n\t\t\t\t\t\tcallFunctions,\n\t\t\t\t\t\tfunction(err, result){\n\t\t\t\t\t\t\tif(err) {\n\t\t\t\t\t\t\t\tconsole.error(err);\n\t\t\t\t\t\t\t\treturn fn(err);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t//console.log(\"succeed.\", result);\n\t\t\t\t\t\treturn fn(err, result);\n\t\t\t\t\t});\n\n\t\t\t\t}\n\t\t\t\n\t\t});\n\n\t},\n\n\t// create rule\n\tcreate: function(key, rule, fn){\n\t\tclient.hmset(key, rule, function(err, result){\n\t\t\tif(err){\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n//\t\t\tconsole.log(\"New rule \", key, \" was created.\");\n\t\t\treturn fn(err, result);\n\t\t});\n\t},\n\n\t// show specific rule\n\tdisplayOne: function(id,fn){\n\t\tclient.hgetall(id, function(err, obj){\n\t\t\tif(err) {\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n\t\t\treturn fn(err, obj);\n\t\t});\n\t},\n\n\t// update rule\n\tupdate: function(key, rule, fn){\n\t\tclient.hmset(key, rule, function(err, result){\n\t\t\tif(err){\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n\t\t\tclient.set(UPDATED_TIME, new Date().getTime(), function(err, result){\n\n\t\t\t});\n//\t\t\tconsole.log(\"rule \", key, \" was updated.\");\n\t\t\treturn fn(err, result);\n\t\t});\n\t},\n\n\t// destroy a rule\n\tdestroy: function(id, fn){\n\t\tclient.hclear(id, function(err, obj){\n\t\t\tif(err) {\n\t\t\t\tconsole.error(err);\n\t\t\t\treturn fn(err);\n\t\t\t}\n//\t\t\tconsole.log(\"one rule:\", id, \" has been detroyed.\");\n\t\t\treturn fn(err, obj);\n\t\t});\n\t}\n\n}\nmodule.exports = drillingRule;"}